{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import boto3\n",
    "import json\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "data_in_bytes = s3.Object('databucket-covid-19', 'covid.json').get()['Body'].read()\n",
    "decoded_data = data_in_bytes.decode('utf-8')\n",
    "stringio_data = io.StringIO(decoded_data)\n",
    "data = stringio_data.readlines()\n",
    "json_content = list(map(json.loads, data))\n",
    "\n",
    "#content_object = s3.Object('databucket-covid-19', 'covid.json')\n",
    "#file_content = content_object.get()['Body'].read().decode('utf-8')\n",
    "#json_content = json.loads(file_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_content[0]['start']\n",
    "dates = []\n",
    "cases = []\n",
    "deaths = []\n",
    "for x in range(len(json_content)):\n",
    "    dates.append(json_content[x]['start'])\n",
    "    cases.append(json_content[x]['target'][0])\n",
    "    deaths.append(json_content[x]['target'][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Cases Over Time')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dates,cases,label='Cases Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Cases')\n",
    "plt.title('Cases Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Deaths Over Time')"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ8AAAEWCAYAAAC5XZqEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3XmcHFW5//HPQxLCEkICGQIkgWGJS8BrwLBc0QvK7nLBnagQvWj0Ai78/N3LiApcBUVEURb5sUWCVwQUgUAiEELYCcmEJRuEDFnIZJ1sk8kyk1me3x91eqYYuqc7w3TV9Mz3/Xr1q0+fOlX1VHV3PXWqqqvN3REREUnSLmkHICIivY+Sj4iIJE7JR0REEqfkIyIiiVPyERGRxCn5iIhI4pR8RApgZm5mh6cdR7GZ2RYzOzTtOKTnU/KRkmNmS81su5nVmdkmM3vBzL5rZl3yeTazp8zsW10xrSzT7m9mvzKzt8MyLDKz/zIzK8b82s370pBctphZvZk1x17PB3D3Ae6+uNixiCj5SKn6rLvvBRwMXA1cAtyRbkgF+RtwMvApYC/gXGA88IeunpGZ9Y2/dvdfhuQyAPgu8GLmtbsf0dXzF+mIko+UNHevdfdJwFeAcWZ2JLT2MK4NPYw1Zvb/zGz3MGywmT1iZjVmtjGUh4dhVwEfB24MPYIbY7M7JfRUNpnZTZneipkdbmZPm1mtma0zs3uzxWpmJwOnAV9w93nu3uTuM4CvAxeG6XzFzCrbjXexmU0qYLlOMrNqM7vEzFYDf9rZ9Rk/vGhmd5rZH83sn2FdPG9m+5vZ78N6e8PMjoqNe6CZ3R/W6xIz+/7Ozl96DyUf6RHcfSZQTZQ4IOoNvQ8YDRwODAMuC8N2IdowHwwcBGwHbgzT+QnwLHBR6BFcFJvNZ4BjgH8BvgycHup/ATwODAaGAzfkCPNU4CV3X94u9pdC7CcDDwPvN7ORsSZfBe4uYLkA9gf2Ccs2PkccO+PLwE+BIUAD8CLwcnj9d+B3AOGQ58PAayGmk4EfmtnpWaYpouQjPcpKYJ/QIxkPXOzuG9y9DvglcA6Au6939/vdfVsYdhVwYgHTv9rdN7n728B0ogQA0Ei0sT/Q3evd/bkc4w8BVuUYtgoY4u7bgIeAsQAhCX0AmJRvuYIW4HJ3b3D37QUsUz4PuPtsd68HHgDq3f0ud28G7gUyPZ9jgDJ3/7m77wjnjW5rF5tIKyUf6UmGARuAMmAPYHY4RLYJeDTUY2Z7mNktZrbMzDYDzwCDzKxPnumvjpW3AQNC+b8BA2aa2Xwz+48c468DDsgx7IAwHKJezthQ/irwYEhKHS5XUBMSRVdZEytvz/I6sw4OBg7MxBViuxQY2oWxSA/SN38Tke7PzI4hSj7PEW3EtwNHuPuKLM1/BLwfOM7dV5vZaOAVogQCsFO3enf31cC3QxwfA54ws2fcvapd0yeIDkWNiB96M7PjgBHAk6FqKlAW4hoLXBzq8y3XTsfehZYDS9x9ZN6WIqjnIyXOzAaa2WeAe4D/dfe57t5CdMjnOjPbL7QbFjv/sBfRRnyTme0DXN5usmuAgn/rYmZfylywAGwkSgAt7du5+xPANOB+MzvCzPqY2fHA/wI3u/ui0K6R6Kq43xCdv5ka6vMtV5pmAnXhYofdw7IdGXYKRN5FyUdK1cNmVke0x/0TohPf34wNvwSoAmaEQ2tPEPV2AH4P7E7Uk5hBdOgq7g/AF8MVXdcXEMsxwEtmtgWYBPygg9/KfIHofNGjwBaixHMH8L127e4GTgH+5u5NBS5XasI5oM8QnQdbQrRubwf2TjMu6b5MfyYnIiJJU89HREQSp+QjIiKJU/IREZHEKfmIiEjiet3vfIYMGeLl5eVphyEiUlJmz569zt3L8rcsTK9LPuXl5VRWVuZvKCIircxsWVdOT4fdREQkcUo+IiKSOCUfERFJnJKPiIgkTslHREQSp+QjIiKJU/IREZHEKfmIiPRwb6zezP+579W0w3gHJR8RkR6opcW5aXr0Z7pfv30m/3h5BVsamvKMlZxed4cDEZHe4MbpVfxu6psMH7w7DU3NADS3dJ//b1PPR0SkB7nw7pdZXVvPhq07AFqfuxv1fEREeojXV21m8pxVrKtr4IMHDEw7nA6p5yMi0kM0NLUAUN/YnHIk+Sn5iIhI4pR8REQkcUVLPmY2wsymm9kCM5tvZj8I9VeY2QozezU8PhUb58dmVmVmC83s9Fj9GaGuyswqYvWHmNlLof5eM9u1WMsjIiJdp5g9nybgR+4+CjgeuNDMRoVh17n76PCYAhCGnQMcAZwB/NHM+phZH+Am4ExgFDA2Np1fh2kdDmwEzi/i8oiISBcpWvJx91Xu/nIo1wGvA8M6GOUs4B53b3D3JUAVcGx4VLn7YnffAdwDnGVmBnwS+HsYfyJwdnGWRkSk+7rsoXk8tXBt2mHslETO+ZhZOXAU8FKousjM5pjZBDMbHOqGActjo1WHulz1+wKb3L2pXX22+Y83s0ozq6ypqemCJRIR6T7uenEZ3/jTrLTD2ClFTz5mNgC4H/ihu28GbgYOA0YDq4DfFjsGd7/V3ce4+5iysrJiz05EpOjOv3MW4ybMTDuMTivqj0zNrB9R4vmLu/8DwN3XxIbfBjwSXq4ARsRGHx7qyFG/HhhkZn1D7yfeXkSkx2lsbqGhqYUB/fsy7Y3SOszWXjGvdjPgDuB1d/9drP6AWLPPAfNCeRJwjpn1N7NDgJHATGAWMDJc2bYr0UUJk9zdgenAF8P444CHirU8IiJp+9dfPcmRlz+Wdhhdopg9nxOAc4G5Zpa5l/elRFerjQYcWAp8B8Dd55vZfcACoivlLnT3ZgAzuwh4DOgDTHD3+WF6lwD3mNmVwCtEyU5EpEdat6Uh7RC6TNGSj7s/B1iWQVM6GOcq4Kos9VOyjefui4muhhMRkRKiOxyIiEjilHxERLqx3019k/KKyayq3Z52KF1KyUdEpJupb2ymvGIyazfXM+Ot9QC8vX5bylF1LSUfEZFuZtKrKwG47ok3U46keJR8RES6gZYWp7xiMj97cB4t7qEu5aCKSMlHRKQbaGqJEs49s95OOZJkKPmIiKTozueX8MSCNfkb9jBFvb2OiIh07IqHFwDw5pVnphxJstTzERGRxCn5iIhI4pR8REQSduOTi/iPO0vr/3e6ms75iIgk7NrHe+7vdwqlno+IiCROyUdERBKn5CMikoA7nltCecVkWsKPSXs7JR8RkQT8Ptynra6hKeVIugclHxERSZySj4hIkbS0OLc+81baYXRLutRaRKRI/vhUFdc+/iYH7L172qF0O+r5iIgUybotO8JzQ8qRdD9KPiIikjglHxGRLtTQFP0F9vSFa9MOpVtT8hER6UKvr6oD4PdTdQudjij5iIhI4pR8REQkcUo+IiJd4BePLODZRTVph1EylHxERLrAHc8t4dw7ZqYdRslQ8hERkcQp+YiISOKKlnzMbISZTTezBWY238x+EOr3MbOpZrYoPA8O9WZm15tZlZnNMbOjY9MaF9ovMrNxsfqPmNncMM71ZmbFWh4Rkfamv7GWaa+vSTuMklTMnk8T8CN3HwUcD1xoZqOACmCau48EpoXXAGcCI8NjPHAzRMkKuBw4DjgWuDyTsEKbb8fGO6OIyyMi8g7fvHMW50+sTDuMklS05OPuq9z95VCuA14HhgFnARNDs4nA2aF8FnCXR2YAg8zsAOB0YKq7b3D3jcBU4IwwbKC7z3B3B+6KTUtERLqxRM75mFk5cBTwEjDU3VeFQauBoaE8DFgeG6061HVUX52lPtv8x5tZpZlV1tToUkgRkbQVPfmY2QDgfuCH7r45Piz0WIr+n7Lufqu7j3H3MWVlZcWenYj0YPWNzaytq087jJJX1ORjZv2IEs9f3P0foXpNOGRGeM7cfW8FMCI2+vBQ11H98Cz1IiJFc9wvp3HsVdPSDqPkFfNqNwPuAF5399/FBk0CMlesjQMeitWfF656Ox6oDYfnHgNOM7PB4UKD04DHwrDNZnZ8mNd5sWmJiBRF7fbGtEPoEYr5T6YnAOcCc83s1VB3KXA1cJ+ZnQ8sA74chk0BPgVUAduAbwK4+wYz+wUwK7T7ubtvCOULgDuB3YF/hoeIiHRzRUs+7v4ckOt3Nydnae/AhTmmNQGYkKW+EjjyPYQpIiIp0B0ORETyWLSmjg9d8RjRPrJ0BSUfEZE8fvrgPOrqm6hctjHtUHoMJR8RkTwyHZ6WFvV8uoqSj4iIJE7JR0REEqfkIyKSxdvrt1FeMZnnFq1LO5QeSclHRCSLF96Kks7Dr61MOZKeSclHREQSp+QjIiKJU/IREYmZuWQDm+t1/7ZiU/IREQmamlv48i0vcvaNz6cdSo+n5CMiEmR+Q7p847Z0A+kFlHxERCRxSj4iIpI4JR8R6fWmLljDq8s3pR1Gr1LMP5MTESkJ376rEoA3rzwz5Uh6D/V8REQkcUo+IiKSOCUfERFJnJKPiPRK81bUMnXBmrTD6LV0wYGI9EqfueE5AJZe/emUI+md1PMREZHEKfmIiEjilHxERCRxSj4iIpI4JR8R6TXWb2ngoVdXpB2GoKvdRKQX+dItL7K4Ziunjdo/7VB6PfV8RKTXqKlrAGBHc0vKkUjRko+ZTTCztWY2L1Z3hZmtMLNXw+NTsWE/NrMqM1toZqfH6s8IdVVmVhGrP8TMXgr195rZrsVaFhER6VrF7PncCZyRpf46dx8dHlMAzGwUcA5wRBjnj2bWx8z6ADcBZwKjgLGhLcCvw7QOBzYC5xdxWUREpAsVLfm4+zPAhgKbnwXc4+4N7r4EqAKODY8qd1/s7juAe4CzzMyATwJ/D+NPBM7u0gUQEZGiKSj5mNk1ZjbQzPqZ2TQzqzGzr3dynheZ2ZxwWG5wqBsGLI+1qQ51uer3BTa5e1O7+lzxjzezSjOrrKmp6WTYIlKK5lRvorxiMss3bEs7FIkptOdzmrtvBj4DLAUOB/6rE/O7GTgMGA2sAn7biWnsNHe/1d3HuPuYsrKyJGYpIt3EP16OLq1+4nXdRLQ7KfRS60y7TwN/c/fa6MjXznH31nffzG4DHgkvVwAjYk2Hhzpy1K8HBplZ39D7ibcXEZFurtCezyNm9gbwEWCamZUB9Ts7MzM7IPbyc0DmSrhJwDlm1t/MDgFGAjOBWcDIcGXbrkQXJUxydwemA18M448DHtrZeEREJB0F9XzcvcLMrgFq3b3ZzLYSXSSQk5n9FTgJGGJm1cDlwElmNhpwosN33wnTn29m9wELgCbgQndvDtO5CHgM6ANMcPf5YRaXAPeY2ZXAK8AdBS+1iIikamfucPABoNzM4uPclauxu4/NUp0zQbj7VcBVWeqnAFOy1C8muhpORERKTEHJx8z+THShwKtAc6h2Okg+IiIiuRTa8xkDjArnWkREurXtO5r54GWPcsPYo9IORXIo9IKDeYDuxCciJWHhmjoAbn92ccqRSC4d9nzM7GGiw2t7AQvMbCbQkBnu7v9e3PBERKQnynfY7dpEohARkV6lw+Tj7k8DmNmv3f2S+DAz+zXwdBFjExGRHqrQcz6nZqk7sysDERGR3iPfOZ//BC4ADjWzObFBewEvFDMwERHpufKd87kb+CfwK6AiVl/n7oX+XYKISCJeqFpH+ZA90w5DCpDvnE8tUAuMBTCz/YDdgAFmNsDd3y5+iCIihfnq7S8B8OCFJ6QcieRT6P/5fNbMFgFLiC4yWErUIxIREdlphV5wcCVwPPCmux8CnAzMKFpUIiLSoxWafBrdfT2wi5nt4u7TiW65IyIistMKvbfbJjMbADwL/MXM1gJbixeWiIj0ZIX2fM4CtgE/BB4F3gI+W6ygRESkZyv0z+S2mtnBwEh3n2hmexD9uZuISKq+/9dXaG5xbvra0WmHIjuh0Kvdvg38HbglVA0DHixWUCIihZr02komz12Vdhiykwo97HYhcAKwGcDdFwH7FSsoERHp2QpNPg3uviPzIvyVtv5YTkREOqXQ5PO0mV0K7G5mpwJ/Ax4uXlgiItKTFZp8KoAaYC7wHWAK8NNiBSUiIj1boVe7tZjZg8CD7l5T5JhERKSH67DnY5ErzGwdsBBYaGY1ZnZZMuGJiLzb81Xr+NmD89IOQ96DfIfdLia6yu0Yd9/H3fcBjgNOMLOLix6diEgWX7v9Jf48Y1naYch7kC/5nAuMdfclmQp3Xwx8HTivmIGJiEjPlS/59HP3de0rw3mffsUJSUREerp8yWdHJ4eJiIjklO9qtw+b2eYs9Ub0j6YiIiI7Ld/faOvmoSIi0uUK/ZHpTjOzCWa21szmxer2MbOpZrYoPA8O9WZm15tZlZnNMbOjY+OMC+0Xmdm4WP1HzGxuGOd6M7NiLYuIiHStoiUf4E7gjHZ1FcA0dx8JTAuvAc4ERobHeOBmiJIVcDnR5d3HApdnElZo8+3YeO3nJSI9yE3TqyivmMzazfVphyJdoGjJx92fATa0qz4LmBjKE4GzY/V3eWQGMMjMDgBOB6a6+wZ33whMBc4Iwwa6+wx3d+Cu2LREpAd6emF0c5Ul6/Qnyj1BMXs+2Qx198wfb6wGhobyMGB5rF11qOuovjpLfVZmNt7MKs2ssqZGdwcSEUlb0smnVeixJPK3DO5+q7uPcfcxZWVlScxSREQ6kHTyWRMOmRGe14b6FcCIWLvhoa6j+uFZ6kVEpAQknXwmAZkr1sYBD8XqzwtXvR0P1IbDc48Bp5nZ4HChwWnAY2HYZjM7Plzldl5sWiIi0s0V9JcKnWFmfwVOAoaYWTXRVWtXA/eZ2fnAMuDLofkU4FNAFbAN+CaAu28ws18As0K7n7t75iKGC4iuqNsd+Gd4iIhICSha8nH3sTkGnZylrQMX5pjOBGBClvpK4Mj3EqOIdG9NzS382zXTmfKDj6cdinSx1C44EBHJ54FXVrCytp5rHluYdijSxZR8RKTbam6JLohtbk7kwlhJkJKPiIgkTslHREQSp+QjIiKJU/IREZHEKfmIiEjilHxEpFtxd8orJvO7qW+mHYoUkZKPiHQrjeGy6pufqko5EikmJR8REUmcko+IiCROyUdERBKn5CMiIolT8hERkcQp+YhIt3DWjc/xswfnpR2GJETJR0S6hdeqa/nzjGVphyEJUfIREZHEKfmIiEjilHxERCRxSj4iIpI4JR8REUmcko+IiCROyUdEUvPdP8/mAz/7Z9phSAr6ph2AiPRej85fnXYIkhL1fEREJHFKPiIikjglHxERSZySj4iIJC6V5GNmS81srpm9amaVoW4fM5tqZovC8+BQb2Z2vZlVmdkcMzs6Np1xof0iMxuXxrKIyM659Zm3KK+YTEuLpx2KpCjNns8n3H20u48JryuAae4+EpgWXgOcCYwMj/HAzRAlK+By4DjgWODyTMISke7rhierAKhraEo5EklTdzrsdhYwMZQnAmfH6u/yyAxgkJkdAJwOTHX3De6+EZgKnJF00CIisvPSSj4OPG5ms81sfKgb6u6rQnk1MDSUhwHLY+NWh7pc9e9iZuPNrNLMKmtqarpqGUREpJPS+pHpx9x9hZntB0w1szfiA93dzazLDgi7+63ArQBjxozRgWYRkZSl0vNx9xXheS3wANE5mzXhcBrheW1ovgIYERt9eKjLVS8iIt1c4snHzPY0s70yZeA0YB4wCchcsTYOeCiUJwHnhavejgdqw+G5x4DTzGxwuNDgtFAnIt3MvBW1lFdMpnrjtrRDkW4ijcNuQ4EHzCwz/7vd/VEzmwXcZ2bnA8uAL4f2U4BPAVXANuCbAO6+wcx+AcwK7X7u7huSWwwRKdTfZ1cDMHXBmpQjke4i8eTj7ouBD2epXw+cnKXegQtzTGsCMKGrYxQRkeLqTpdai4hIL6HkIyIiiVPyERGRxCn5iEhRNLc45RWTmbVU1wHJuyn5iEhRzF1RC8CVjyxIORLpjpR8REQkcUo+IiKSOCUfERFJnJKPiIgkTslHRLpUecVkTvzN9LTDkG5OyUdEutyy9bqBqHRMyUdERBKn5CMiIolT8hGR96y8YjLlFZPTDkNKiJKPiIgkTslHREQSp+QjIp2ydnM9L761Pu0wpESl8TfaItIDHPvLaQAsvfrTKUcipUg9HxERSZySj4gUzN1ZsWl72mFID6DkIyIF+5+HF3DC1U+yfIPuYCDvjZKPiBRswcrNAKxU70feIyUfEenQ1oYmyismq7cjXUrJR0Q69PBrKwG48cmqlCORnkTJR0Texd0pr5jMDdMWpR2K9FBKPiLyLo3NDsD1Tyr5SHEo+YhIq2/8aSbXPPpG2mFIL6DkI9LL3fXiUv7rb68B8NTCGv741FvpBiS9gpKPSC/09Js1HB9uj3PZQ/P52+zqlCOSrtDi0eHSrTuaWV1bD0BDUwt19U1RA08rsncr+eRjZmeY2UIzqzKzirTjEeluFq2po7nFWbJuK+UVk1m3pYHv3f0yqzfXs7m+Me3wSkJjS0uHw93btur1jc0AbNvRzNq6+jCc1gQQb7t+S0Nred7K2mhezc5fZ74NwJwVtcxcugGAVSGZALxVs6W1/Micla3lH90X9WCr1m7h0fmrAbj92cWtwxuamzte0ASVdPIxsz7ATcCZwChgrJmNSjcqkY41NkcbspYWZ9uOaIPU0NTM1oaovLauntrtUVKYv7K2tc2dzy+hucWpq2/k90+8CcBryzdx0/ToEujbn13MLU9Hh8zKKybznT9XsmLTdk697hkuuX8OE19YCkSXTmc2f97Fe8LxDWtTc9sGO5Pk4hvhHU1tw9fFNsLLN0a/J2psdqrWbmkdf+n6rQAsi/3eKPOjV4h6cxn3VS4H4LXqWu4Myz19YU3rvO+d9XZr2/jG+bKH5rXOu+Ifc6O2lct55e1NAPzkwXmtbS++99XW8tk3Pd9aPufWGQAsWruFKXOjBPDzRxa0Dv/cH19oLZ923TOt5c/H6l+rjhLR66valu+Hsfn9+w3PtZYvuvuV1vKSdVtpb92WHe+q6w7Mu/rTlyAz+1fgCnc/Pbz+MYC7/yrXOGPGjPHKysqdnte3Js5i2Xr9yK43W11bT11IEBlDB/ZnzeZowzlyvwEsChvLeHnIgP7v2Li2V77vHiwNn634eIeW7cnimndvTLLJNe/d+/Vhe2Puvd2yvfpTUxfFtv/A3Vi9Odq7HrxHPzZuK6xXtNdufVs36v377kJDU8e9hJ4ivm4P3Hs3VsZ6Jh3p18daryY8cthA5q2IEswpH9yPJ15fW9A0jjpoUGtC/MqYEdwbku1po4by+II1Oceb9ZNTKNurf0HzaM/MZrv7mE6NnEWp/6XCMGB57HU1cFz7RmY2HhgPcNBBB3VqRgftsye79i3pjqK8RyP22YMn31jLcYfsQ31TC68t38ToEYOYU13Lqtp6Rg6NJYBQ3m+v/hx90GAenb+aDw3bmwH9+/Li4vV84v1lLN+4naq1Wxh14EDWb9lBXUNT63h77NqHD+y/F4trtnJo2Z6U77vnu+Z9+hFDOzXvU0cNZWrYQJ1w2L48+Gp02ObE95W1bsTOOHJ//jpzOUMG7MrHR5bxwCsr+MT7y1ixaTtvrtnC2GMPaj009IWjh7f2Lr7x0XJueSbqSXzvk4dzw5NVHHXQIA4rG8DfZ1fz1eMO4qk31rKytp4fnDyS6o3bqdnSwInvK2NO9SZ269uH0QcN4vH5q3n//gM54sCBTJ6ziiOHDWS/gbvxfNU6xpTvw+79+vDa8k0cddAgarc3smLjdj42cgjf+NMs9turP3eMO4bP3vgcX/rIcD5/9HDG3jaDa7/0YWrqGvj1o29w/39+lN8/8SbPLlrH1Iv/jVOve4bd+/XhuUs+wUeufIJTRw3ll5/7EMdc9QS/+eK/cMDeu/P1O15i2o9O5C8z3mbC80t45r8/wVdueZHF67by5P89iQ/87FE+eti+/Pn84zjs0in89NMf5PQj9ufj10znke99jNeqN/GTB+Yx89JT+P49r/DsonU8cMEJjPzJPzm0bE9uO28Mh/x4Ct858VAuOOlwPvw/j3P3t4+joamFb/5pFrN/egrXT1vExBeXce/4f+Wk30xn3dYdXP2FD3Fv5XI+8y8HcP05R3HopVP4wzmjOXLY3pz826d5vuKT3PbMYu58YSmD9uiX2Pcln1Lv+XwROMPdvxVenwsc5+4X5Rqnsz0fEZHerKt7PqW+K78CGBF7PTzUiYhIN1bqyWcWMNLMDjGzXYFzgEkpxyQiInmU9Dkfd28ys4uAx4A+wAR3n59yWCIikkdJJx8Ad58CTEk7DhERKVypH3YTEZESpOQjIiKJU/IREZHEKfmIiEjiSvpHpp1hZjXAsk6OPgRY10E53/CuHk/z1rw1b827M+N1xsHuXvYexn8nd9ejwAdQ2VE53/CuHk/z1rw1b827M+N1h4cOu4mISOKUfEREJHFKPjvn1jzlfMO7ejzNW/PWvDXvzoyXul53wYGIiKRPPR8REUmcko+IiCSupG8samYjgLuAoUR3td4FcKJ/OM0sW3Oo6xfaWHht7coiIj1dtu1dI9H20WPDG4ENwCZgf2AQ0ba0DtgN2BGeW4DNYdjewCKgCbjA3Wd2FEip93yagB+5+yjg08CuwLeAB4lWyL8Trcj5wJ1EK/R/gUqilTUfeD3U7yD6IzoPrzM/xno7zAfgidi83wrPmfaZcra6+Ik1b/fckcY8wwuZRq55Z6vPN14h4jFvj5W3xcotWcZrjpVrY+X6WDn+B/dNdCweczym5hxtstXF592QZ37FFF9f+d6LeMybckyjJUtdfB119r3P1bY5R31n5tHVcq2DXOsjI9cy1eco55t3R++x52gHbd+DZmB9KC+L1VfR9n3fQrQ93ABsDXXVoe1bwLGh/CRRYhkUxtklTP+vYfw7iP5LbTrweeBDRNvPf7j7aOAy4Jo8y17aycfdV7n7y6FcBbwK9AfGALOJ3qhmop7QicCLwCeAfYlW1v6hfTNt2R6ijVz/UI4nnONoe4OH0vahyMwnw4j2EDJlo+3DkOlt5UoE8Q/XmvaL/K6V8M5pZIbHvzgWq8/Vw8uWDOLzs3avs5Uzr2ti9bvTtl6h0tSoAAAGHklEQVT6x+rj8WXm3RCbxurY8F1j9YNj9ZnpvpcNZaZ9c6wcTzL9Y/X5vivt12H7nYyO3ruMHTmG5Xvf2m8IM+PtEavLFv8O3rn+M7J9Zpzsn5P4TkCuZB6fd0uWtrmWr6PPW0fDc8msp1yf9/iRoKYc5fh3PtvwfrFytvnkWu5cy7I91q6ZtqM7GY2hfhNRsmsAFhId5Wki2k5ltm19wrgDiHYGG4i2hVuJPiuZ8sFE28ZG4P1EyaqBKMlsBc4ErgYmAmcTfeeHEu3UQ9QDWpll2dutiW7wS9eueADlRL2UgUS9nreBI4k+AJtidZlyS1h5m8Mb8mZ48xx4lrYNUgVtX7wm2r6wTaG+vl05s1FbFhsv/px5bI6V4+PF221pN077R0uOclOe8bbnmE6u6WUe2wqY98I8884V39s51ke+R8NOtG0sYLzmPNPItl4KGa+QaeSqz/fobMzx+s2dnMfOxJzrM9PZ5c733uea7o4C2sQ/o81Z2mYb3tXvd2OWabfw7u9PS2xaDbT1auKP7WFambbbYtOuD6+raDu0tjpMaxXRDnhdrN0O4NfAAqKd8fHAPKLv8HKiI0gH94o7HJjZAOB+4IdEK3YPoqQxkbYN7R5huAN7huefxcrLifZ0G4gy9y5Eb/IPwmxaiPYcGmNliN7oTDmz99gEHBAbD9o+JBl9spTbt4n3Fmg3LDOfjPjeb+Z9dbKLH9Zy2vasLEtdrvHih9Hi8z40xzzj8+uTpX5ArLxru2G5ehXty7n2aDPiyxTfy40fHsl3qDMuvv7zfZc2x8rx9bUzh9Ti4uPlO2cZjzM+Xvw9jK//bHKt83xyHb7amcOfudZR+89Je/H7mMXjiH/+ch1OjX8ns32f4uVcvcps4us8X48vsw2C7IelPTY9J9r49yXqfW0Pjy1EPZddY+2c6KhKdShvCG2XEn1O64HbQvvM/LcRHVlaEMb5LPAdotMW1wIbgYvdfQRwMdGhuQ6V/O98zKwf8AjRX2nfEMpHEZ3PeRi4ADiQ6E04E3iO6I2oDo/jiVbcYKI3tREoI/rwxLvQmQ/YdqLDSRB9KeKH1frG6tt/ILPVJSVXMklCM9mTjeTX2fctzfdb0tP+u5Z5ndk2ZT4XTUTbos1EO9oQJaBMuYVoOzeQd+6QbiPajrYQJe1LiU5j/Eemvbu7mRlQ6+4DOwq2pHs+YSHvIMq+18XKNUSJ4zqiPboNRL2gyUQrcw5RT+gI4A2iE2vbifYc9qWt+7oLUY8os9f6LG17EMvC8Hjiifdy2h8n7mjvKdceQHwvqbN7CU3kP2eTT2fbVtL2ZYjvCeY7Ab0iVo73GOI9r/YXHLSPMdcefnxPN9tybYmV4z2iuvYNC9TZ9y2eQDa1q+9IY47xsvU0ck0rvtz5emaF9GZy9bwycvUSulq2+OPnJuKfjfjnLt+5rvjnK36RTb47SMd7Y9ty1MfPbcYfmRgaYsNfi42/nGibs5K2c3iZ9zVzSG0PoiM3TUTbyR+H+N8gOnLUQLStnEX0Hn2L6EKEtWG880LcTUQ78ieG6X+S6Kq3DpV0z8fMPkaUEOYS9UYOJzpGeQBtxzb7Eq30PrT1ZOK9EO0likhv0dH2Lp4MMlf81hElpgOJksw2om3nLrQlvruITnv8gbbt7QXuPrujQEo6+YiISGkq6cNuIiJSmpR8REQkcUo+IiKSOCUfERFJnJKPiIgkrqTvai3SnZnZvsC08HJ/ot9sZO59t83dP5pKYCLdgC61FkmAmV0BbHH3a9OORaQ70GE3kRSY2ZbwfJKZPW1mD5nZYjO72sy+ZmYzzWyumR0W2pWZ2f1mNis8Tkh3CUTeGyUfkfR9GPgu8EHgXOB97n4scDvwvdDmD8B17n4M8IUwTKRk6ZyPSPpmufsqADN7C3g81M8lunEjwCnAqOh2hgAMNLMB7r4FkRKk5COSvvgNLVtirzP3JoToKMXx7p7v3zFFSoIOu4mUhsdpOwSHmY1OMRaR90zJR6Q0fB8YY2ZzzGwB0TkikZKlS61FRCRx6vmIiEjilHxERCRxSj4iIpI4JR8REUmcko+IiCROyUdERBKn5CMiIon7//KNI3JBZoiLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(dates,deaths,label='Deaths Over Time')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Deaths')\n",
    "plt.title('Deaths Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_session = boto3.session.Session()\n",
    "my_region = my_session.region_name\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(my_region, \"forecasting-deepar\", \"latest\")\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.c4.2xlarge',\n",
    "    base_job_name='covid-19-deepar',\n",
    "    output_path='s3://databucket-covid-19/'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_length = 20\n",
    "context_length = 20\n",
    "hyperparameters = {\n",
    "    \"time_freq\": 'D',\n",
    "    \"epochs\": \"400\",\n",
    "    \"early_stopping_patience\": \"40\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context_length),\n",
    "    \"prediction_length\": str(prediction_length)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-05-10 18:31:01 Starting - Starting the training job...\n",
      "2020-05-10 18:31:04 Starting - Launching requested ML instances......\n",
      "2020-05-10 18:32:09 Starting - Preparing the instances for training...\n",
      "2020-05-10 18:33:00 Downloading - Downloading input data...\n",
      "2020-05-10 18:33:29 Training - Downloading the training image...\n",
      "2020-05-10 18:33:44 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'20', u'epochs': u'400', u'time_freq': u'D', u'context_length': u'20', u'mini_batch_size': u'64', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'400', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'20', u'time_freq': u'D', u'context_length': u'20', u'_kvstore': u'auto', u'early_stopping_patience': u'40'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Using early stopping with patience 40\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] [cardinality=auto] `cat` field was found in the file `/opt/ml/input/data/train/covid.json` and will be used for training.\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/covid.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] [cardinality=auto] Inferred value of cardinality=[55] from dataset.\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Training set statistics:\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Integer time series\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] number of time series: 55\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] number of observations: 3699\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] mean target length: 67\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] min/mean/max target: 1.0/8190.96458502/335804.0\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] mean abs(target): 8190.96458502\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] contains missing values: no\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Small number of time series. Doing 12 passes over dataset with prob 0.969696969697 per epoch.\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] nvidia-smi took: 0.0251791477203 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:46 INFO 140026428319552] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 92.47803688049316, \"sum\": 92.47803688049316, \"min\": 92.47803688049316}}, \"EndTime\": 1589135627.061855, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135626.968538}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 236.51599884033203, \"sum\": 236.51599884033203, \"min\": 236.51599884033203}}, \"EndTime\": 1589135627.205183, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135627.061931}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] Epoch[0] Batch[0] avg_epoch_loss=9.920926\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=9.92092609406\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] Epoch[0] Batch[5] avg_epoch_loss=9.634351\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=9.63435061773\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] Epoch[0] Batch [5]#011Speed: 1486.79 samples/sec#011loss=9.634351\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] Epoch[0] Batch[10] avg_epoch_loss=9.286685\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=8.86948699951\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] Epoch[0] Batch [10]#011Speed: 1340.92 samples/sec#011loss=8.869487\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 400, \"sum\": 400.0, \"min\": 400}, \"update.time\": {\"count\": 1, \"max\": 753.978967666626, \"sum\": 753.978967666626, \"min\": 753.978967666626}}, \"EndTime\": 1589135627.959327, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135627.205244}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=924.281664955 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=0, train loss <loss>=9.28668533672\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:47 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_992858c1-ed9b-4726-a7e4-874290eb6f97-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.115873336791992, \"sum\": 23.115873336791992, \"min\": 23.115873336791992}}, \"EndTime\": 1589135627.983167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135627.959406}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] Epoch[1] Batch[0] avg_epoch_loss=8.260736\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=8.26073646545\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] Epoch[1] Batch[5] avg_epoch_loss=7.936122\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=7.93612178167\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] Epoch[1] Batch [5]#011Speed: 1371.59 samples/sec#011loss=7.936122\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] Epoch[1] Batch[10] avg_epoch_loss=7.980655\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=8.03409519196\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] Epoch[1] Batch [10]#011Speed: 1337.55 samples/sec#011loss=8.034095\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 690.2492046356201, \"sum\": 690.2492046356201, \"min\": 690.2492046356201}}, \"EndTime\": 1589135628.673558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135627.983243}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=986.440394753 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=1, train loss <loss>=7.98065514998\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_89b40fa3-10e6-49e2-b407-ea98678b5bec-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.276121139526367, \"sum\": 16.276121139526367, \"min\": 16.276121139526367}}, \"EndTime\": 1589135628.690366, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135628.673634}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] Epoch[2] Batch[0] avg_epoch_loss=7.738347\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=7.73834705353\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] Epoch[2] Batch[5] avg_epoch_loss=7.717121\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=7.71712136269\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] Epoch[2] Batch [5]#011Speed: 1083.68 samples/sec#011loss=7.717121\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] processed a total of 613 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 830.3689956665039, \"sum\": 830.3689956665039, \"min\": 830.3689956665039}}, \"EndTime\": 1589135629.520853, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135628.690427}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=738.124717437 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] #progress_metric: host=algo-1, completed 0 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=2, train loss <loss>=7.59177207947\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_923c7108-d7f3-416f-9aba-3fa3e9b75cf8-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.823125839233398, \"sum\": 15.823125839233398, \"min\": 15.823125839233398}}, \"EndTime\": 1589135629.537302, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135629.520929}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] Epoch[3] Batch[0] avg_epoch_loss=7.505480\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=7.50548028946\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Epoch[3] Batch[5] avg_epoch_loss=7.479391\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=7.47939062119\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Epoch[3] Batch [5]#011Speed: 1377.90 samples/sec#011loss=7.479391\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Epoch[3] Batch[10] avg_epoch_loss=7.415780\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=7.33944721222\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Epoch[3] Batch [10]#011Speed: 1238.87 samples/sec#011loss=7.339447\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] processed a total of 685 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 733.3791255950928, \"sum\": 733.3791255950928, \"min\": 733.3791255950928}}, \"EndTime\": 1589135630.270822, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135629.537374}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=933.885033679 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=3, train loss <loss>=7.41577998075\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_11761bfe-9004-4c76-94b0-e5d282190f42-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.711069107055664, \"sum\": 15.711069107055664, \"min\": 15.711069107055664}}, \"EndTime\": 1589135630.287106, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135630.270897}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Epoch[4] Batch[0] avg_epoch_loss=6.834374\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=6.83437395096\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Epoch[4] Batch[5] avg_epoch_loss=7.091905\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=7.09190511703\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Epoch[4] Batch [5]#011Speed: 1398.30 samples/sec#011loss=7.091905\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 655.534029006958, \"sum\": 655.534029006958, \"min\": 655.534029006958}}, \"EndTime\": 1589135630.94277, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135630.287176}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=962.416816548 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=4, train loss <loss>=7.03426589966\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:50 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_270af768-455d-431a-a4f8-5bd06a39fac3-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.159130096435547, \"sum\": 15.159130096435547, \"min\": 15.159130096435547}}, \"EndTime\": 1589135630.958562, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135630.942841}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] Epoch[5] Batch[0] avg_epoch_loss=7.345995\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=7.34599494934\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] Epoch[5] Batch[5] avg_epoch_loss=6.949501\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=6.9495010376\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] Epoch[5] Batch [5]#011Speed: 1130.64 samples/sec#011loss=6.949501\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] Epoch[5] Batch[10] avg_epoch_loss=7.019431\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=7.10334663391\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] Epoch[5] Batch [10]#011Speed: 1348.04 samples/sec#011loss=7.103347\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 742.8250312805176, \"sum\": 742.8250312805176, \"min\": 742.8250312805176}}, \"EndTime\": 1589135631.701519, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135630.958628}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=926.041704079 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=5, train loss <loss>=7.0194308541\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_49ce5193-0c90-46ca-aa33-b164032ba39d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.766071319580078, \"sum\": 16.766071319580078, \"min\": 16.766071319580078}}, \"EndTime\": 1589135631.718852, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135631.701601}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] Epoch[6] Batch[0] avg_epoch_loss=6.784762\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=6.78476238251\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Epoch[6] Batch[5] avg_epoch_loss=6.838069\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=6.83806888262\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Epoch[6] Batch [5]#011Speed: 1460.20 samples/sec#011loss=6.838069\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 598.6180305480957, \"sum\": 598.6180305480957, \"min\": 598.6180305480957}}, \"EndTime\": 1589135632.317585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135631.718916}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1047.25148576 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=6, train loss <loss>=6.93409733772\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_174580eb-9901-4497-8f35-f58b6550e9cc-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.493797302246094, \"sum\": 16.493797302246094, \"min\": 16.493797302246094}}, \"EndTime\": 1589135632.334698, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135632.317646}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Epoch[7] Batch[0] avg_epoch_loss=6.565862\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=6.56586170197\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Epoch[7] Batch[5] avg_epoch_loss=6.648565\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=6.64856537183\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Epoch[7] Batch [5]#011Speed: 1449.71 samples/sec#011loss=6.648565\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Epoch[7] Batch[10] avg_epoch_loss=6.573134\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=6.48261528015\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] Epoch[7] Batch [10]#011Speed: 1434.30 samples/sec#011loss=6.482615\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 659.235954284668, \"sum\": 659.235954284668, \"min\": 659.235954284668}}, \"EndTime\": 1589135632.994059, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135632.334764}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1043.45805059 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=7, train loss <loss>=6.57313351198\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:52 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_696d3e2d-be05-4a34-b114-b1980678d09b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.831087112426758, \"sum\": 17.831087112426758, \"min\": 17.831087112426758}}, \"EndTime\": 1589135633.012465, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135632.994131}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] Epoch[8] Batch[0] avg_epoch_loss=6.562677\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=6.56267738342\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] Epoch[8] Batch[5] avg_epoch_loss=6.651665\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=6.6516652902\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] Epoch[8] Batch [5]#011Speed: 1232.85 samples/sec#011loss=6.651665\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] Epoch[8] Batch[10] avg_epoch_loss=6.613107\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=6.56683692932\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] Epoch[8] Batch [10]#011Speed: 1356.03 samples/sec#011loss=6.566837\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 717.7479267120361, \"sum\": 717.7479267120361, \"min\": 717.7479267120361}}, \"EndTime\": 1589135633.730351, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135633.012537}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=961.195653401 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=8, train loss <loss>=6.61310694434\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] Epoch[9] Batch[0] avg_epoch_loss=6.224704\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=6.22470426559\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Epoch[9] Batch[5] avg_epoch_loss=6.587162\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=6.58716233571\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Epoch[9] Batch [5]#011Speed: 1303.73 samples/sec#011loss=6.587162\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Epoch[9] Batch[10] avg_epoch_loss=6.434111\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=6.25044879913\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Epoch[9] Batch [10]#011Speed: 1152.03 samples/sec#011loss=6.250449\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 730.111837387085, \"sum\": 730.111837387085, \"min\": 730.111837387085}}, \"EndTime\": 1589135634.461001, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135633.730422}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=915.852359863 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=9, train loss <loss>=6.43411072818\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_03078913-fc5e-407c-898d-cffc4296eb88-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.008014678955078, \"sum\": 21.008014678955078, \"min\": 21.008014678955078}}, \"EndTime\": 1589135634.483433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135634.461295}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Epoch[10] Batch[0] avg_epoch_loss=6.802183\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=6.80218267441\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Epoch[10] Batch[5] avg_epoch_loss=6.408768\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=6.40876785914\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:54 INFO 140026428319552] Epoch[10] Batch [5]#011Speed: 1411.92 samples/sec#011loss=6.408768\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Epoch[10] Batch[10] avg_epoch_loss=6.437857\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=6.47276496887\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Epoch[10] Batch [10]#011Speed: 1339.90 samples/sec#011loss=6.472765\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] processed a total of 676 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 682.3940277099609, \"sum\": 682.3940277099609, \"min\": 682.3940277099609}}, \"EndTime\": 1589135635.165948, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135634.483502}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=990.473242528 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=10, train loss <loss>=6.43785745447\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Epoch[11] Batch[0] avg_epoch_loss=6.482941\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=6.48294115067\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Epoch[11] Batch[5] avg_epoch_loss=6.327937\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=6.32793688774\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Epoch[11] Batch [5]#011Speed: 1462.51 samples/sec#011loss=6.327937\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Epoch[11] Batch[10] avg_epoch_loss=6.321356\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=6.31345911026\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Epoch[11] Batch [10]#011Speed: 1382.77 samples/sec#011loss=6.313459\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] processed a total of 699 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 675.4229068756104, \"sum\": 675.4229068756104, \"min\": 675.4229068756104}}, \"EndTime\": 1589135635.841858, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135635.166024}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1034.73694843 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=11, train loss <loss>=6.3213560798\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:55 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_3b4dbcd4-995d-453d-ab59-815a5a0bb388-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.630929946899414, \"sum\": 22.630929946899414, \"min\": 22.630929946899414}}, \"EndTime\": 1589135635.86504, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135635.841935}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[12] Batch[0] avg_epoch_loss=6.443983\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=6.443983078\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[12] Batch[5] avg_epoch_loss=6.245221\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=6.24522074064\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[12] Batch [5]#011Speed: 1496.94 samples/sec#011loss=6.245221\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[12] Batch[10] avg_epoch_loss=6.401708\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=6.58949232101\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[12] Batch [10]#011Speed: 1385.19 samples/sec#011loss=6.589492\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] processed a total of 655 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 662.1689796447754, \"sum\": 662.1689796447754, \"min\": 662.1689796447754}}, \"EndTime\": 1589135636.527326, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135635.865104}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=989.012175502 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=12, train loss <loss>=6.40170782263\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[13] Batch[0] avg_epoch_loss=6.434024\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=6.43402433395\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[13] Batch[5] avg_epoch_loss=6.282088\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=6.28208796183\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:56 INFO 140026428319552] Epoch[13] Batch [5]#011Speed: 1363.56 samples/sec#011loss=6.282088\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] Epoch[13] Batch[10] avg_epoch_loss=6.136646\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=5.96211557388\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] Epoch[13] Batch [10]#011Speed: 1412.17 samples/sec#011loss=5.962116\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 684.0670108795166, \"sum\": 684.0670108795166, \"min\": 684.0670108795166}}, \"EndTime\": 1589135637.211876, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135636.527402}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=958.789593153 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=13, train loss <loss>=6.13664596731\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_51c3c9ea-fdef-4e6b-bdea-89ea2c20775e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 21.95882797241211, \"sum\": 21.95882797241211, \"min\": 21.95882797241211}}, \"EndTime\": 1589135637.234382, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135637.21197}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] Epoch[14] Batch[0] avg_epoch_loss=6.008256\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=6.00825595856\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] Epoch[14] Batch[5] avg_epoch_loss=6.217557\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=6.21755719185\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] Epoch[14] Batch [5]#011Speed: 1472.19 samples/sec#011loss=6.217557\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] processed a total of 615 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 614.1068935394287, \"sum\": 614.1068935394287, \"min\": 614.1068935394287}}, \"EndTime\": 1589135637.848597, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135637.234435}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1001.26811659 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=14, train loss <loss>=6.0964322567\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:57 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_a309c5fb-83cd-4fbc-b63a-c99f4d34c7c0-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.708105087280273, \"sum\": 23.708105087280273, \"min\": 23.708105087280273}}, \"EndTime\": 1589135637.87289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135637.848678}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] Epoch[15] Batch[0] avg_epoch_loss=6.309505\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=6.30950546265\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] Epoch[15] Batch[5] avg_epoch_loss=6.048846\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=6.04884624481\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] Epoch[15] Batch [5]#011Speed: 1389.96 samples/sec#011loss=6.048846\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] Epoch[15] Batch[10] avg_epoch_loss=6.134646\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=6.23760671616\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] Epoch[15] Batch [10]#011Speed: 1284.58 samples/sec#011loss=6.237607\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] processed a total of 741 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 770.9801197052002, \"sum\": 770.9801197052002, \"min\": 770.9801197052002}}, \"EndTime\": 1589135638.643985, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135637.87295}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=960.967177248 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=15, train loss <loss>=6.21549181143\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] Epoch[16] Batch[0] avg_epoch_loss=5.882505\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=5.88250541687\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Epoch[16] Batch[5] avg_epoch_loss=5.995960\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=5.99595952034\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Epoch[16] Batch [5]#011Speed: 1493.90 samples/sec#011loss=5.995960\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Epoch[16] Batch[10] avg_epoch_loss=5.834047\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=5.6397521019\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Epoch[16] Batch [10]#011Speed: 1432.63 samples/sec#011loss=5.639752\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 681.3249588012695, \"sum\": 681.3249588012695, \"min\": 681.3249588012695}}, \"EndTime\": 1589135639.325827, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135638.644066}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=972.946982046 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=16, train loss <loss>=5.83404705741\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_a7e3c302-b826-4ca3-b159-112ecf19962d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.225099563598633, \"sum\": 16.225099563598633, \"min\": 16.225099563598633}}, \"EndTime\": 1589135639.34259, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135639.325903}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Epoch[17] Batch[0] avg_epoch_loss=5.397303\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=5.39730262756\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Epoch[17] Batch[5] avg_epoch_loss=5.808607\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=5.80860702197\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:33:59 INFO 140026428319552] Epoch[17] Batch [5]#011Speed: 1345.31 samples/sec#011loss=5.808607\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Epoch[17] Batch[10] avg_epoch_loss=5.698056\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=5.56539440155\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Epoch[17] Batch [10]#011Speed: 1262.70 samples/sec#011loss=5.565394\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 731.7109107971191, \"sum\": 731.7109107971191, \"min\": 731.7109107971191}}, \"EndTime\": 1589135640.074432, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135639.342663}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=929.18616747 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=17, train loss <loss>=5.69805583087\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_334f1e4b-5375-4afd-9fe6-1d33ea8c8182-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.978118896484375, \"sum\": 18.978118896484375, \"min\": 18.978118896484375}}, \"EndTime\": 1589135640.093937, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135640.074509}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Epoch[18] Batch[0] avg_epoch_loss=6.201318\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=6.20131826401\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Epoch[18] Batch[5] avg_epoch_loss=5.887021\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=5.88702130318\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Epoch[18] Batch [5]#011Speed: 1451.61 samples/sec#011loss=5.887021\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] processed a total of 588 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 605.5638790130615, \"sum\": 605.5638790130615, \"min\": 605.5638790130615}}, \"EndTime\": 1589135640.699625, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135640.093999}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=970.811597067 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #progress_metric: host=algo-1, completed 4 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=18, train loss <loss>=5.49469096661\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_f19b58fa-4c77-4e6a-8787-9565e5fe472b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.609161376953125, \"sum\": 23.609161376953125, \"min\": 23.609161376953125}}, \"EndTime\": 1589135640.723835, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135640.699704}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] Epoch[19] Batch[0] avg_epoch_loss=5.787521\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=5.78752088547\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Epoch[19] Batch[5] avg_epoch_loss=5.699845\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=5.69984507561\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Epoch[19] Batch [5]#011Speed: 1456.69 samples/sec#011loss=5.699845\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Epoch[19] Batch[10] avg_epoch_loss=5.474881\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=5.20492386818\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Epoch[19] Batch [10]#011Speed: 1318.64 samples/sec#011loss=5.204924\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 674.0009784698486, \"sum\": 674.0009784698486, \"min\": 674.0009784698486}}, \"EndTime\": 1589135641.397995, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135640.723908}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=995.391181113 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] #quality_metric: host=algo-1, epoch=19, train loss <loss>=5.47488089041\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_876bb553-1079-412b-98ec-f3be503b2e7b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.71600341796875, \"sum\": 16.71600341796875, \"min\": 16.71600341796875}}, \"EndTime\": 1589135641.415263, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135641.398064}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Epoch[20] Batch[0] avg_epoch_loss=5.646671\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=5.64667081833\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Epoch[20] Batch[5] avg_epoch_loss=5.664049\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=5.66404922803\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:01 INFO 140026428319552] Epoch[20] Batch [5]#011Speed: 1476.57 samples/sec#011loss=5.664049\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] Epoch[20] Batch[10] avg_epoch_loss=5.813422\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=5.99266996384\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] Epoch[20] Batch [10]#011Speed: 1431.87 samples/sec#011loss=5.992670\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 691.3471221923828, \"sum\": 691.3471221923828, \"min\": 691.3471221923828}}, \"EndTime\": 1589135642.106751, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135641.415342}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=944.382613361 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #quality_metric: host=algo-1, epoch=20, train loss <loss>=5.81342228976\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] Epoch[21] Batch[0] avg_epoch_loss=5.411250\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=5.4112496376\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] Epoch[21] Batch[5] avg_epoch_loss=5.646669\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=5.64666922887\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] Epoch[21] Batch [5]#011Speed: 1368.97 samples/sec#011loss=5.646669\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 638.0410194396973, \"sum\": 638.0410194396973, \"min\": 638.0410194396973}}, \"EndTime\": 1589135642.745278, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135642.106827}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1002.88817555 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #quality_metric: host=algo-1, epoch=21, train loss <loss>=5.77969284058\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] Epoch[22] Batch[0] avg_epoch_loss=5.934810\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:02 INFO 140026428319552] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=5.93480968475\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] Epoch[22] Batch[5] avg_epoch_loss=5.500719\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=5.50071914991\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] Epoch[22] Batch [5]#011Speed: 1491.29 samples/sec#011loss=5.500719\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] Epoch[22] Batch[10] avg_epoch_loss=5.592547\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=5.70274133682\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] Epoch[22] Batch [10]#011Speed: 1203.92 samples/sec#011loss=5.702741\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 694.6098804473877, \"sum\": 694.6098804473877, \"min\": 694.6098804473877}}, \"EndTime\": 1589135643.440412, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135642.745358}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=970.174992887 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] #quality_metric: host=algo-1, epoch=22, train loss <loss>=5.59254741669\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] Epoch[23] Batch[0] avg_epoch_loss=5.565648\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=5.56564760208\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] Epoch[23] Batch[5] avg_epoch_loss=5.622091\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=5.62209113439\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:03 INFO 140026428319552] Epoch[23] Batch [5]#011Speed: 1483.82 samples/sec#011loss=5.622091\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[23] Batch[10] avg_epoch_loss=5.622667\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=5.62335767746\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[23] Batch [10]#011Speed: 1355.13 samples/sec#011loss=5.623358\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] processed a total of 696 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 672.605037689209, \"sum\": 672.605037689209, \"min\": 672.605037689209}}, \"EndTime\": 1589135644.113481, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135643.440487}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1034.6241821 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #quality_metric: host=algo-1, epoch=23, train loss <loss>=5.62266683578\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[24] Batch[0] avg_epoch_loss=6.348694\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=6.34869432449\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[24] Batch[5] avg_epoch_loss=5.603408\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=5.60340778033\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[24] Batch [5]#011Speed: 1410.26 samples/sec#011loss=5.603408\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[24] Batch[10] avg_epoch_loss=5.743250\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=5.91106023788\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[24] Batch [10]#011Speed: 1362.50 samples/sec#011loss=5.911060\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 669.4390773773193, \"sum\": 669.4390773773193, \"min\": 669.4390773773193}}, \"EndTime\": 1589135644.783436, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135644.113551}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=969.293331501 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #quality_metric: host=algo-1, epoch=24, train loss <loss>=5.74324980649\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] Epoch[25] Batch[0] avg_epoch_loss=5.705494\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:04 INFO 140026428319552] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=5.705493927\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] Epoch[25] Batch[5] avg_epoch_loss=5.562850\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=5.56285007795\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] Epoch[25] Batch [5]#011Speed: 1480.80 samples/sec#011loss=5.562850\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 597.7301597595215, \"sum\": 597.7301597595215, \"min\": 597.7301597595215}}, \"EndTime\": 1589135645.381757, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135644.78352}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1067.17716563 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] #quality_metric: host=algo-1, epoch=25, train loss <loss>=5.49508047104\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] Epoch[26] Batch[0] avg_epoch_loss=5.779698\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=5.77969837189\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] Epoch[26] Batch[5] avg_epoch_loss=5.655985\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=5.65598495801\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:05 INFO 140026428319552] Epoch[26] Batch [5]#011Speed: 1483.65 samples/sec#011loss=5.655985\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[26] Batch[10] avg_epoch_loss=5.571812\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=5.47080440521\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[26] Batch [10]#011Speed: 1415.65 samples/sec#011loss=5.470804\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 646.4710235595703, \"sum\": 646.4710235595703, \"min\": 646.4710235595703}}, \"EndTime\": 1589135646.028824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135645.381825}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1051.66914454 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #quality_metric: host=algo-1, epoch=26, train loss <loss>=5.57181197947\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[27] Batch[0] avg_epoch_loss=5.739356\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=5.73935604095\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[27] Batch[5] avg_epoch_loss=5.411102\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=5.41110173861\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[27] Batch [5]#011Speed: 1475.10 samples/sec#011loss=5.411102\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[27] Batch[10] avg_epoch_loss=5.481175\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=5.5652630806\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[27] Batch [10]#011Speed: 1425.03 samples/sec#011loss=5.565263\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] processed a total of 680 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 645.9081172943115, \"sum\": 645.9081172943115, \"min\": 645.9081172943115}}, \"EndTime\": 1589135646.675307, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135646.028907}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1052.58588786 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #quality_metric: host=algo-1, epoch=27, train loss <loss>=5.48117507588\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] Epoch[28] Batch[0] avg_epoch_loss=5.449903\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:06 INFO 140026428319552] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=5.44990253448\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Epoch[28] Batch[5] avg_epoch_loss=5.432751\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=5.43275062243\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Epoch[28] Batch [5]#011Speed: 1477.45 samples/sec#011loss=5.432751\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Epoch[28] Batch[10] avg_epoch_loss=5.402394\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=5.36596508026\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Epoch[28] Batch [10]#011Speed: 1361.75 samples/sec#011loss=5.365965\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] processed a total of 641 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 648.2980251312256, \"sum\": 648.2980251312256, \"min\": 648.2980251312256}}, \"EndTime\": 1589135647.324138, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135646.675387}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=988.572284151 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] #quality_metric: host=algo-1, epoch=28, train loss <loss>=5.40239355781\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_a203c9ed-0a81-4133-be52-e8052114f16d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 24.255037307739258, \"sum\": 24.255037307739258, \"min\": 24.255037307739258}}, \"EndTime\": 1589135647.348944, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135647.324214}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Epoch[29] Batch[0] avg_epoch_loss=5.683237\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=5.68323707581\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Epoch[29] Batch[5] avg_epoch_loss=5.372561\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=5.37256105741\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:07 INFO 140026428319552] Epoch[29] Batch [5]#011Speed: 1484.59 samples/sec#011loss=5.372561\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] Epoch[29] Batch[10] avg_epoch_loss=5.437073\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=5.51448802948\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] Epoch[29] Batch [10]#011Speed: 1267.45 samples/sec#011loss=5.514488\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 685.9631538391113, \"sum\": 685.9631538391113, \"min\": 685.9631538391113}}, \"EndTime\": 1589135648.035038, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135647.349017}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=953.253890494 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #quality_metric: host=algo-1, epoch=29, train loss <loss>=5.43707331744\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] Epoch[30] Batch[0] avg_epoch_loss=5.318253\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=5.31825256348\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] Epoch[30] Batch[5] avg_epoch_loss=5.395132\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=5.39513222377\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] Epoch[30] Batch [5]#011Speed: 1502.25 samples/sec#011loss=5.395132\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 617.4771785736084, \"sum\": 617.4771785736084, \"min\": 617.4771785736084}}, \"EndTime\": 1589135648.653012, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135648.035112}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1034.6435291 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #quality_metric: host=algo-1, epoch=30, train loss <loss>=5.37634148598\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_a50ca829-b646-43a2-9478-0b29328c31ed-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.90599250793457, \"sum\": 23.90599250793457, \"min\": 23.90599250793457}}, \"EndTime\": 1589135648.677439, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135648.653085}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] Epoch[31] Batch[0] avg_epoch_loss=5.411621\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:08 INFO 140026428319552] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=5.41162061691\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] Epoch[31] Batch[5] avg_epoch_loss=5.340551\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=5.34055066109\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] Epoch[31] Batch [5]#011Speed: 1483.43 samples/sec#011loss=5.340551\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] Epoch[31] Batch[10] avg_epoch_loss=5.405994\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=5.48452663422\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] Epoch[31] Batch [10]#011Speed: 1384.72 samples/sec#011loss=5.484527\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] processed a total of 701 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 667.8900718688965, \"sum\": 667.8900718688965, \"min\": 667.8900718688965}}, \"EndTime\": 1589135649.34544, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135648.677498}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1049.40272276 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] #quality_metric: host=algo-1, epoch=31, train loss <loss>=5.40599428524\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] Epoch[32] Batch[0] avg_epoch_loss=5.417631\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=5.41763067245\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] Epoch[32] Batch[5] avg_epoch_loss=5.438723\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=5.43872324626\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:09 INFO 140026428319552] Epoch[32] Batch [5]#011Speed: 1095.11 samples/sec#011loss=5.438723\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 705.0430774688721, \"sum\": 705.0430774688721, \"min\": 705.0430774688721}}, \"EndTime\": 1589135650.050971, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135649.345516}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=904.771870839 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #quality_metric: host=algo-1, epoch=32, train loss <loss>=5.39500546455\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] Epoch[33] Batch[0] avg_epoch_loss=4.967195\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=4.96719455719\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] Epoch[33] Batch[5] avg_epoch_loss=5.224213\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=5.22421344121\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] Epoch[33] Batch [5]#011Speed: 1484.85 samples/sec#011loss=5.224213\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] Epoch[33] Batch[10] avg_epoch_loss=5.421815\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=5.65893783569\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] Epoch[33] Batch [10]#011Speed: 1285.46 samples/sec#011loss=5.658938\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 664.9420261383057, \"sum\": 664.9420261383057, \"min\": 664.9420261383057}}, \"EndTime\": 1589135650.71648, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135650.051043}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=996.913191708 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #quality_metric: host=algo-1, epoch=33, train loss <loss>=5.4218154387\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] Epoch[34] Batch[0] avg_epoch_loss=5.392399\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:10 INFO 140026428319552] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=5.39239883423\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] Epoch[34] Batch[5] avg_epoch_loss=5.416403\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=5.41640329361\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] Epoch[34] Batch [5]#011Speed: 1472.08 samples/sec#011loss=5.416403\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] Epoch[34] Batch[10] avg_epoch_loss=5.436159\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=5.45986642838\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] Epoch[34] Batch [10]#011Speed: 1307.95 samples/sec#011loss=5.459866\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] processed a total of 686 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 667.7470207214355, \"sum\": 667.7470207214355, \"min\": 667.7470207214355}}, \"EndTime\": 1589135651.384792, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135650.716552}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1027.15363292 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #quality_metric: host=algo-1, epoch=34, train loss <loss>=5.43615926396\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] Epoch[35] Batch[0] avg_epoch_loss=5.741852\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=5.74185180664\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] Epoch[35] Batch[5] avg_epoch_loss=5.551701\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=5.55170075099\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] Epoch[35] Batch [5]#011Speed: 1495.64 samples/sec#011loss=5.551701\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 594.1920280456543, \"sum\": 594.1920280456543, \"min\": 594.1920280456543}}, \"EndTime\": 1589135651.979534, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135651.384873}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1049.95532833 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] #quality_metric: host=algo-1, epoch=35, train loss <loss>=5.43187880516\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:11 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] Epoch[36] Batch[0] avg_epoch_loss=4.999032\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=4.99903202057\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] Epoch[36] Batch[5] avg_epoch_loss=5.307405\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=5.30740483602\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] Epoch[36] Batch [5]#011Speed: 1467.03 samples/sec#011loss=5.307405\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] Epoch[36] Batch[10] avg_epoch_loss=5.510975\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=5.75525960922\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] Epoch[36] Batch [10]#011Speed: 1376.12 samples/sec#011loss=5.755260\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] processed a total of 652 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 651.4410972595215, \"sum\": 651.4410972595215, \"min\": 651.4410972595215}}, \"EndTime\": 1589135652.631601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135651.979616}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1000.67080374 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] #quality_metric: host=algo-1, epoch=36, train loss <loss>=5.51097518748\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] Epoch[37] Batch[0] avg_epoch_loss=5.712047\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:12 INFO 140026428319552] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=5.71204662323\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[37] Batch[5] avg_epoch_loss=5.751690\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=5.7516904672\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[37] Batch [5]#011Speed: 1497.85 samples/sec#011loss=5.751690\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[37] Batch[10] avg_epoch_loss=5.596889\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=5.41112670898\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[37] Batch [10]#011Speed: 1449.52 samples/sec#011loss=5.411127\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 637.714147567749, \"sum\": 637.714147567749, \"min\": 637.714147567749}}, \"EndTime\": 1589135653.2699, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135652.631684}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1031.6409398 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #quality_metric: host=algo-1, epoch=37, train loss <loss>=5.59688875892\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[38] Batch[0] avg_epoch_loss=5.329506\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=5.32950639725\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[38] Batch[5] avg_epoch_loss=5.486033\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=5.48603328069\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[38] Batch [5]#011Speed: 1403.00 samples/sec#011loss=5.486033\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[38] Batch[10] avg_epoch_loss=5.346751\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=5.17961235046\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Epoch[38] Batch [10]#011Speed: 1441.60 samples/sec#011loss=5.179612\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 653.7728309631348, \"sum\": 653.7728309631348, \"min\": 653.7728309631348}}, \"EndTime\": 1589135653.924167, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135653.26997}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1044.53740242 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #progress_metric: host=algo-1, completed 9 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] #quality_metric: host=algo-1, epoch=38, train loss <loss>=5.34675103968\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:13 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_ac4059c6-073c-48ab-857f-107614aeaa5e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 16.294002532958984, \"sum\": 16.294002532958984, \"min\": 16.294002532958984}}, \"EndTime\": 1589135653.941011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135653.924232}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] Epoch[39] Batch[0] avg_epoch_loss=5.709589\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=5.70958852768\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] Epoch[39] Batch[5] avg_epoch_loss=5.361184\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=5.36118356387\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] Epoch[39] Batch [5]#011Speed: 1387.42 samples/sec#011loss=5.361184\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] Epoch[39] Batch[10] avg_epoch_loss=5.323558\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=5.27840738297\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] Epoch[39] Batch [10]#011Speed: 1352.10 samples/sec#011loss=5.278407\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] processed a total of 695 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 687.7760887145996, \"sum\": 687.7760887145996, \"min\": 687.7760887145996}}, \"EndTime\": 1589135654.628888, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135653.941061}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1010.33447663 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] #quality_metric: host=algo-1, epoch=39, train loss <loss>=5.32355802709\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_53a69819-aa38-4532-9dc9-2e2a1726a286-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 25.732040405273438, \"sum\": 25.732040405273438, \"min\": 25.732040405273438}}, \"EndTime\": 1589135654.655194, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135654.628966}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] Epoch[40] Batch[0] avg_epoch_loss=5.477709\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:14 INFO 140026428319552] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=5.47770929337\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] Epoch[40] Batch[5] avg_epoch_loss=5.160975\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=5.1609749794\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] Epoch[40] Batch [5]#011Speed: 1465.10 samples/sec#011loss=5.160975\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 659.7449779510498, \"sum\": 659.7449779510498, \"min\": 659.7449779510498}}, \"EndTime\": 1589135655.315071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135654.655264}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=966.870516108 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] #quality_metric: host=algo-1, epoch=40, train loss <loss>=5.19734797478\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_10d6d1a4-848e-4b97-a0a4-b781bea834ca-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.292137145996094, \"sum\": 22.292137145996094, \"min\": 22.292137145996094}}, \"EndTime\": 1589135655.337945, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135655.315152}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] Epoch[41] Batch[0] avg_epoch_loss=5.532798\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=5.53279829025\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] Epoch[41] Batch[5] avg_epoch_loss=5.429621\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=5.42962129911\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:15 INFO 140026428319552] Epoch[41] Batch [5]#011Speed: 1445.03 samples/sec#011loss=5.429621\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[41] Batch[10] avg_epoch_loss=5.536418\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=5.66457490921\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[41] Batch [10]#011Speed: 1369.79 samples/sec#011loss=5.664575\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 669.1849231719971, \"sum\": 669.1849231719971, \"min\": 669.1849231719971}}, \"EndTime\": 1589135656.00725, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135655.338014}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=962.209481415 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #quality_metric: host=algo-1, epoch=41, train loss <loss>=5.53641839461\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[42] Batch[0] avg_epoch_loss=4.950548\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=4.95054769516\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[42] Batch[5] avg_epoch_loss=5.024550\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=5.02455027898\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[42] Batch [5]#011Speed: 1510.94 samples/sec#011loss=5.024550\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[42] Batch[10] avg_epoch_loss=5.068417\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=5.1210565567\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[42] Batch [10]#011Speed: 1360.76 samples/sec#011loss=5.121057\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 656.7330360412598, \"sum\": 656.7330360412598, \"min\": 656.7330360412598}}, \"EndTime\": 1589135656.664514, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135656.007323}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1018.49611039 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #quality_metric: host=algo-1, epoch=42, train loss <loss>=5.06841676885\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_5b656ea8-d286-4ffd-8e22-305aafbeef99-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.083074569702148, \"sum\": 15.083074569702148, \"min\": 15.083074569702148}}, \"EndTime\": 1589135656.680178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135656.664595}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] Epoch[43] Batch[0] avg_epoch_loss=5.395315\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:16 INFO 140026428319552] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=5.39531469345\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] Epoch[43] Batch[5] avg_epoch_loss=5.099287\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=5.09928743045\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] Epoch[43] Batch [5]#011Speed: 1486.59 samples/sec#011loss=5.099287\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] Epoch[43] Batch[10] avg_epoch_loss=5.231270\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=5.3896484375\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] Epoch[43] Batch [10]#011Speed: 1270.46 samples/sec#011loss=5.389648\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] processed a total of 651 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 673.3078956604004, \"sum\": 673.3078956604004, \"min\": 673.3078956604004}}, \"EndTime\": 1589135657.35359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135656.680228}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=966.711430914 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] #quality_metric: host=algo-1, epoch=43, train loss <loss>=5.23126970638\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] Epoch[44] Batch[0] avg_epoch_loss=5.457391\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=5.45739126205\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] Epoch[44] Batch[5] avg_epoch_loss=5.337485\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=5.337485075\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:17 INFO 140026428319552] Epoch[44] Batch [5]#011Speed: 1482.30 samples/sec#011loss=5.337485\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] Epoch[44] Batch[10] avg_epoch_loss=5.190215\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=5.01349124908\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] Epoch[44] Batch [10]#011Speed: 1439.41 samples/sec#011loss=5.013491\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 671.6940402984619, \"sum\": 671.6940402984619, \"min\": 671.6940402984619}}, \"EndTime\": 1589135658.025776, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135657.353666}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=957.127186236 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #quality_metric: host=algo-1, epoch=44, train loss <loss>=5.19021515413\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] Epoch[45] Batch[0] avg_epoch_loss=4.797354\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=4.79735422134\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] Epoch[45] Batch[5] avg_epoch_loss=5.452692\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=5.45269171397\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] Epoch[45] Batch [5]#011Speed: 1395.73 samples/sec#011loss=5.452692\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] processed a total of 627 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 631.3779354095459, \"sum\": 631.3779354095459, \"min\": 631.3779354095459}}, \"EndTime\": 1589135658.657627, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135658.025849}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=992.888344883 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #quality_metric: host=algo-1, epoch=45, train loss <loss>=5.37671160698\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] Epoch[46] Batch[0] avg_epoch_loss=5.188254\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:18 INFO 140026428319552] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=5.18825387955\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Epoch[46] Batch[5] avg_epoch_loss=5.182030\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=5.18202980359\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Epoch[46] Batch [5]#011Speed: 1477.10 samples/sec#011loss=5.182030\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] processed a total of 637 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 617.1989440917969, \"sum\": 617.1989440917969, \"min\": 617.1989440917969}}, \"EndTime\": 1589135659.275356, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135658.657706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1031.8884044 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #quality_metric: host=algo-1, epoch=46, train loss <loss>=5.20181875229\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Epoch[47] Batch[0] avg_epoch_loss=5.233407\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=5.23340654373\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Epoch[47] Batch[5] avg_epoch_loss=5.201467\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=5.2014670372\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Epoch[47] Batch [5]#011Speed: 1417.91 samples/sec#011loss=5.201467\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Epoch[47] Batch[10] avg_epoch_loss=4.783500\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=4.28194022179\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Epoch[47] Batch [10]#011Speed: 1392.38 samples/sec#011loss=4.281940\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] processed a total of 643 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 688.5998249053955, \"sum\": 688.5998249053955, \"min\": 688.5998249053955}}, \"EndTime\": 1589135659.964472, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135659.275436}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=933.628281319 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] #quality_metric: host=algo-1, epoch=47, train loss <loss>=4.78350030292\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:19 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_d67e6bfb-0357-4cbc-aae1-745b342c312d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 24.016141891479492, \"sum\": 24.016141891479492, \"min\": 24.016141891479492}}, \"EndTime\": 1589135659.989011, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135659.964549}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] Epoch[48] Batch[0] avg_epoch_loss=5.159785\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=5.15978527069\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] Epoch[48] Batch[5] avg_epoch_loss=5.057549\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=5.05754852295\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] Epoch[48] Batch [5]#011Speed: 1448.86 samples/sec#011loss=5.057549\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] Epoch[48] Batch[10] avg_epoch_loss=5.077500\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=5.10144147873\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] Epoch[48] Batch [10]#011Speed: 1401.55 samples/sec#011loss=5.101441\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 669.7978973388672, \"sum\": 669.7978973388672, \"min\": 669.7978973388672}}, \"EndTime\": 1589135660.658918, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135659.989069}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1004.60976848 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] #quality_metric: host=algo-1, epoch=48, train loss <loss>=5.07749986649\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] Epoch[49] Batch[0] avg_epoch_loss=4.936268\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:20 INFO 140026428319552] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=4.93626785278\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] Epoch[49] Batch[5] avg_epoch_loss=5.079028\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=5.07902844747\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] Epoch[49] Batch [5]#011Speed: 1498.74 samples/sec#011loss=5.079028\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 646.8491554260254, \"sum\": 646.8491554260254, \"min\": 646.8491554260254}}, \"EndTime\": 1589135661.306284, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135660.659}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=986.141496153 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #quality_metric: host=algo-1, epoch=49, train loss <loss>=5.10119996071\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] Epoch[50] Batch[0] avg_epoch_loss=5.517509\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=5.51750850677\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] Epoch[50] Batch[5] avg_epoch_loss=5.153026\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=5.15302562714\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] Epoch[50] Batch [5]#011Speed: 1403.34 samples/sec#011loss=5.153026\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] Epoch[50] Batch[10] avg_epoch_loss=5.125016\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=5.09140453339\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] Epoch[50] Batch [10]#011Speed: 1435.82 samples/sec#011loss=5.091405\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] processed a total of 667 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 684.0910911560059, \"sum\": 684.0910911560059, \"min\": 684.0910911560059}}, \"EndTime\": 1589135661.990903, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135661.306366}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=974.858365064 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] #quality_metric: host=algo-1, epoch=50, train loss <loss>=5.12501603907\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:21 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] Epoch[51] Batch[0] avg_epoch_loss=5.031972\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=5.03197193146\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] Epoch[51] Batch[5] avg_epoch_loss=5.274247\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=5.27424701055\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] Epoch[51] Batch [5]#011Speed: 1379.81 samples/sec#011loss=5.274247\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] Epoch[51] Batch[10] avg_epoch_loss=5.272727\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=5.27090330124\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] Epoch[51] Batch [10]#011Speed: 1423.58 samples/sec#011loss=5.270903\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] processed a total of 669 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 705.4500579833984, \"sum\": 705.4500579833984, \"min\": 705.4500579833984}}, \"EndTime\": 1589135662.696857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135661.990979}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=948.183045301 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] #quality_metric: host=algo-1, epoch=51, train loss <loss>=5.27272714268\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] Epoch[52] Batch[0] avg_epoch_loss=4.992076\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:22 INFO 140026428319552] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=4.9920759201\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] Epoch[52] Batch[5] avg_epoch_loss=4.940736\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=4.94073573748\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] Epoch[52] Batch [5]#011Speed: 1488.48 samples/sec#011loss=4.940736\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] Epoch[52] Batch[10] avg_epoch_loss=4.971713\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=5.00888614655\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] Epoch[52] Batch [10]#011Speed: 1418.56 samples/sec#011loss=5.008886\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 688.2898807525635, \"sum\": 688.2898807525635, \"min\": 688.2898807525635}}, \"EndTime\": 1589135663.385626, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135662.696932}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=999.418898724 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] #quality_metric: host=algo-1, epoch=52, train loss <loss>=4.97171319615\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] Epoch[53] Batch[0] avg_epoch_loss=5.333448\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=5.3334479332\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] Epoch[53] Batch[5] avg_epoch_loss=5.158240\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=5.15824039777\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:23 INFO 140026428319552] Epoch[53] Batch [5]#011Speed: 1375.06 samples/sec#011loss=5.158240\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] Epoch[53] Batch[10] avg_epoch_loss=4.709190\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=4.17033060342\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] Epoch[53] Batch [10]#011Speed: 1369.34 samples/sec#011loss=4.170331\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] processed a total of 648 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 679.9900531768799, \"sum\": 679.9900531768799, \"min\": 679.9900531768799}}, \"EndTime\": 1589135664.066101, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135663.385702}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=952.802444977 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #quality_metric: host=algo-1, epoch=53, train loss <loss>=4.70919049125\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_66144a75-abaf-462d-bdaa-ec13c18d7d15-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 15.831947326660156, \"sum\": 15.831947326660156, \"min\": 15.831947326660156}}, \"EndTime\": 1589135664.082456, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135664.066176}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] Epoch[54] Batch[0] avg_epoch_loss=4.977781\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=4.97778081894\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] Epoch[54] Batch[5] avg_epoch_loss=5.224402\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=5.22440218925\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] Epoch[54] Batch [5]#011Speed: 1399.87 samples/sec#011loss=5.224402\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 660.9570980072021, \"sum\": 660.9570980072021, \"min\": 660.9570980072021}}, \"EndTime\": 1589135664.743532, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135664.082519}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=940.89461944 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #quality_metric: host=algo-1, epoch=54, train loss <loss>=5.1997320652\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] Epoch[55] Batch[0] avg_epoch_loss=4.973563\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:24 INFO 140026428319552] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=4.97356319427\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] Epoch[55] Batch[5] avg_epoch_loss=5.257873\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=5.25787266095\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] Epoch[55] Batch [5]#011Speed: 1431.25 samples/sec#011loss=5.257873\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] Epoch[55] Batch[10] avg_epoch_loss=5.118192\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=4.95057573318\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] Epoch[55] Batch [10]#011Speed: 1401.17 samples/sec#011loss=4.950576\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 685.5840682983398, \"sum\": 685.5840682983398, \"min\": 685.5840682983398}}, \"EndTime\": 1589135665.429685, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135664.743613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1003.36165101 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] #quality_metric: host=algo-1, epoch=55, train loss <loss>=5.11819223924\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] Epoch[56] Batch[0] avg_epoch_loss=5.225188\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=5.22518777847\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] Epoch[56] Batch[5] avg_epoch_loss=5.145184\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=5.14518435796\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:25 INFO 140026428319552] Epoch[56] Batch [5]#011Speed: 1492.04 samples/sec#011loss=5.145184\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[56] Batch[10] avg_epoch_loss=5.106701\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=5.06052150726\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[56] Batch [10]#011Speed: 1438.13 samples/sec#011loss=5.060522\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] processed a total of 697 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 680.6178092956543, \"sum\": 680.6178092956543, \"min\": 680.6178092956543}}, \"EndTime\": 1589135666.11079, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135665.429761}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1023.90531722 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #quality_metric: host=algo-1, epoch=56, train loss <loss>=5.10670124401\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[57] Batch[0] avg_epoch_loss=5.390358\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=5.39035844803\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[57] Batch[5] avg_epoch_loss=4.970498\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=4.97049752871\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[57] Batch [5]#011Speed: 1472.70 samples/sec#011loss=4.970498\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[57] Batch[10] avg_epoch_loss=4.974936\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=4.98026123047\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[57] Batch [10]#011Speed: 1421.40 samples/sec#011loss=4.980261\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] processed a total of 679 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 662.4650955200195, \"sum\": 662.4650955200195, \"min\": 662.4650955200195}}, \"EndTime\": 1589135666.773732, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135666.110865}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1024.79590533 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #quality_metric: host=algo-1, epoch=57, train loss <loss>=4.97493557497\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] Epoch[58] Batch[0] avg_epoch_loss=4.918031\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:26 INFO 140026428319552] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=4.91803121567\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] Epoch[58] Batch[5] avg_epoch_loss=4.975101\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=4.97510067622\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] Epoch[58] Batch [5]#011Speed: 1479.78 samples/sec#011loss=4.975101\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] processed a total of 623 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 610.2011203765869, \"sum\": 610.2011203765869, \"min\": 610.2011203765869}}, \"EndTime\": 1589135667.38443, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135666.773804}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1020.78101767 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] #progress_metric: host=algo-1, completed 14 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] #quality_metric: host=algo-1, epoch=58, train loss <loss>=5.02979216576\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] Epoch[59] Batch[0] avg_epoch_loss=4.831955\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=4.83195543289\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] Epoch[59] Batch[5] avg_epoch_loss=5.026281\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=5.02628103892\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:27 INFO 140026428319552] Epoch[59] Batch [5]#011Speed: 1274.17 samples/sec#011loss=5.026281\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] Epoch[59] Batch[10] avg_epoch_loss=5.226443\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=5.46663818359\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] Epoch[59] Batch [10]#011Speed: 1409.39 samples/sec#011loss=5.466638\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 701.8299102783203, \"sum\": 701.8299102783203, \"min\": 701.8299102783203}}, \"EndTime\": 1589135668.086769, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135667.384511}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=961.616650171 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #quality_metric: host=algo-1, epoch=59, train loss <loss>=5.22644337741\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] Epoch[60] Batch[0] avg_epoch_loss=5.171402\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=5.17140197754\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] Epoch[60] Batch[5] avg_epoch_loss=4.925470\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=4.92546955744\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] Epoch[60] Batch [5]#011Speed: 1303.59 samples/sec#011loss=4.925470\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] processed a total of 624 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 640.6440734863281, \"sum\": 640.6440734863281, \"min\": 640.6440734863281}}, \"EndTime\": 1589135668.727894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135668.086848}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=973.805598726 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #quality_metric: host=algo-1, epoch=60, train loss <loss>=4.85134572983\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] Epoch[61] Batch[0] avg_epoch_loss=4.670884\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:28 INFO 140026428319552] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=4.67088365555\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] Epoch[61] Batch[5] avg_epoch_loss=4.974744\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=4.97474439939\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] Epoch[61] Batch [5]#011Speed: 1340.62 samples/sec#011loss=4.974744\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] processed a total of 630 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 635.0200176239014, \"sum\": 635.0200176239014, \"min\": 635.0200176239014}}, \"EndTime\": 1589135669.363466, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135668.727999}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=991.911854466 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] #quality_metric: host=algo-1, epoch=61, train loss <loss>=5.00461764336\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] Epoch[62] Batch[0] avg_epoch_loss=5.219674\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=5.21967411041\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] Epoch[62] Batch[5] avg_epoch_loss=4.998767\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=4.99876689911\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:29 INFO 140026428319552] Epoch[62] Batch [5]#011Speed: 1262.52 samples/sec#011loss=4.998767\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[62] Batch[10] avg_epoch_loss=4.894970\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=4.77041435242\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[62] Batch [10]#011Speed: 1433.73 samples/sec#011loss=4.770414\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] processed a total of 683 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 696.5830326080322, \"sum\": 696.5830326080322, \"min\": 696.5830326080322}}, \"EndTime\": 1589135670.060589, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135669.363547}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=980.344120949 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #quality_metric: host=algo-1, epoch=62, train loss <loss>=4.89497028698\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[63] Batch[0] avg_epoch_loss=5.397602\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=5.39760160446\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[63] Batch[5] avg_epoch_loss=5.299509\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=5.29950873057\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[63] Batch [5]#011Speed: 1508.35 samples/sec#011loss=5.299509\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[63] Batch[10] avg_epoch_loss=5.109808\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=4.88216619492\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[63] Batch [10]#011Speed: 1420.48 samples/sec#011loss=4.882166\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] processed a total of 671 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 663.5770797729492, \"sum\": 663.5770797729492, \"min\": 663.5770797729492}}, \"EndTime\": 1589135670.724676, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135670.060665}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1011.01404093 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #quality_metric: host=algo-1, epoch=63, train loss <loss>=5.109807578\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] Epoch[64] Batch[0] avg_epoch_loss=4.778657\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:30 INFO 140026428319552] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=4.77865743637\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] Epoch[64] Batch[5] avg_epoch_loss=4.943843\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=4.9438431263\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] Epoch[64] Batch [5]#011Speed: 1452.34 samples/sec#011loss=4.943843\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] Epoch[64] Batch[10] avg_epoch_loss=5.037020\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=5.14883136749\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] Epoch[64] Batch [10]#011Speed: 1419.40 samples/sec#011loss=5.148831\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 698.4360218048096, \"sum\": 698.4360218048096, \"min\": 698.4360218048096}}, \"EndTime\": 1589135671.423592, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135670.724754}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=966.292935561 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] #quality_metric: host=algo-1, epoch=64, train loss <loss>=5.03701959957\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] Epoch[65] Batch[0] avg_epoch_loss=5.158910\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=5.15891027451\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] Epoch[65] Batch[5] avg_epoch_loss=5.052975\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=5.05297525724\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:31 INFO 140026428319552] Epoch[65] Batch [5]#011Speed: 1261.36 samples/sec#011loss=5.052975\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 646.9249725341797, \"sum\": 646.9249725341797, \"min\": 646.9249725341797}}, \"EndTime\": 1589135672.071033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135671.423667}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=978.299550423 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #quality_metric: host=algo-1, epoch=65, train loss <loss>=5.01072030067\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] Epoch[66] Batch[0] avg_epoch_loss=5.450648\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=5.45064783096\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] Epoch[66] Batch[5] avg_epoch_loss=5.219329\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=5.21932872136\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] Epoch[66] Batch [5]#011Speed: 1480.42 samples/sec#011loss=5.219329\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] Epoch[66] Batch[10] avg_epoch_loss=5.128353\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=5.01918201447\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] Epoch[66] Batch [10]#011Speed: 1440.42 samples/sec#011loss=5.019182\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] processed a total of 646 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 645.5278396606445, \"sum\": 645.5278396606445, \"min\": 645.5278396606445}}, \"EndTime\": 1589135672.717081, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135672.071113}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1000.56402805 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #quality_metric: host=algo-1, epoch=66, train loss <loss>=5.1283529455\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] Epoch[67] Batch[0] avg_epoch_loss=4.782590\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:32 INFO 140026428319552] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=4.78258991241\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] Epoch[67] Batch[5] avg_epoch_loss=4.907943\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=4.90794261297\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] Epoch[67] Batch [5]#011Speed: 1497.26 samples/sec#011loss=4.907943\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] Epoch[67] Batch[10] avg_epoch_loss=4.838945\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=4.75614786148\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] Epoch[67] Batch [10]#011Speed: 1440.22 samples/sec#011loss=4.756148\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 691.241979598999, \"sum\": 691.241979598999, \"min\": 691.241979598999}}, \"EndTime\": 1589135673.408797, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135672.717156}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=958.994620185 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] #quality_metric: host=algo-1, epoch=67, train loss <loss>=4.83894499865\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] Epoch[68] Batch[0] avg_epoch_loss=4.792142\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=4.79214191437\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] Epoch[68] Batch[5] avg_epoch_loss=4.819715\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=4.81971478462\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:33 INFO 140026428319552] Epoch[68] Batch [5]#011Speed: 1452.64 samples/sec#011loss=4.819715\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Epoch[68] Batch[10] avg_epoch_loss=4.526595\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=4.17485232353\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Epoch[68] Batch [10]#011Speed: 1385.85 samples/sec#011loss=4.174852\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 691.9970512390137, \"sum\": 691.9970512390137, \"min\": 691.9970512390137}}, \"EndTime\": 1589135674.101255, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135673.40887}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=931.93687569 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #quality_metric: host=algo-1, epoch=68, train loss <loss>=4.52659548413\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/state_787b1a6f-6b8f-4ae6-a80f-63c0afc1770b-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.942947387695312, \"sum\": 23.942947387695312, \"min\": 23.942947387695312}}, \"EndTime\": 1589135674.125728, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135674.101331}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Epoch[69] Batch[0] avg_epoch_loss=4.990588\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=4.99058771133\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Epoch[69] Batch[5] avg_epoch_loss=5.102685\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=5.10268481572\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Epoch[69] Batch [5]#011Speed: 1450.77 samples/sec#011loss=5.102685\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Epoch[69] Batch[10] avg_epoch_loss=4.827505\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=4.49728975296\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] Epoch[69] Batch [10]#011Speed: 1333.67 samples/sec#011loss=4.497290\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 672.6980209350586, \"sum\": 672.6980209350586, \"min\": 672.6980209350586}}, \"EndTime\": 1589135674.798538, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135674.125787}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1001.77320065 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] #quality_metric: host=algo-1, epoch=69, train loss <loss>=4.82750524174\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:34 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[70] Batch[0] avg_epoch_loss=4.930391\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #quality_metric: host=algo-1, epoch=70, batch=0 train loss <loss>=4.93039131165\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[70] Batch[5] avg_epoch_loss=4.936087\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #quality_metric: host=algo-1, epoch=70, batch=5 train loss <loss>=4.9360871315\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[70] Batch [5]#011Speed: 1405.19 samples/sec#011loss=4.936087\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[70] Batch[10] avg_epoch_loss=4.941391\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #quality_metric: host=algo-1, epoch=70, batch=10 train loss <loss>=4.9477563858\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[70] Batch [10]#011Speed: 1408.43 samples/sec#011loss=4.947756\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 667.7520275115967, \"sum\": 667.7520275115967, \"min\": 667.7520275115967}}, \"EndTime\": 1589135675.466842, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135674.798613}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=985.239194631 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #quality_metric: host=algo-1, epoch=70, train loss <loss>=4.941391338\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[71] Batch[0] avg_epoch_loss=4.886492\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #quality_metric: host=algo-1, epoch=71, batch=0 train loss <loss>=4.88649225235\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[71] Batch[5] avg_epoch_loss=4.765281\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] #quality_metric: host=algo-1, epoch=71, batch=5 train loss <loss>=4.76528088252\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:35 INFO 140026428319552] Epoch[71] Batch [5]#011Speed: 1450.39 samples/sec#011loss=4.765281\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 633.4209442138672, \"sum\": 633.4209442138672, \"min\": 633.4209442138672}}, \"EndTime\": 1589135676.100734, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135675.466916}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1010.19490724 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #quality_metric: host=algo-1, epoch=71, train loss <loss>=4.82019147873\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] Epoch[72] Batch[0] avg_epoch_loss=4.943182\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #quality_metric: host=algo-1, epoch=72, batch=0 train loss <loss>=4.94318246841\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] Epoch[72] Batch[5] avg_epoch_loss=5.035129\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #quality_metric: host=algo-1, epoch=72, batch=5 train loss <loss>=5.03512867292\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] Epoch[72] Batch [5]#011Speed: 1463.76 samples/sec#011loss=5.035129\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] Epoch[72] Batch[10] avg_epoch_loss=4.913414\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #quality_metric: host=algo-1, epoch=72, batch=10 train loss <loss>=4.7673573494\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] Epoch[72] Batch [10]#011Speed: 1413.88 samples/sec#011loss=4.767357\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] processed a total of 661 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 663.4418964385986, \"sum\": 663.4418964385986, \"min\": 663.4418964385986}}, \"EndTime\": 1589135676.764758, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135676.100815}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=996.155752472 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] #quality_metric: host=algo-1, epoch=72, train loss <loss>=4.91341443495\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:36 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[73] Batch[0] avg_epoch_loss=4.997871\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #quality_metric: host=algo-1, epoch=73, batch=0 train loss <loss>=4.99787092209\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[73] Batch[5] avg_epoch_loss=4.933024\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #quality_metric: host=algo-1, epoch=73, batch=5 train loss <loss>=4.9330236117\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[73] Batch [5]#011Speed: 1480.84 samples/sec#011loss=4.933024\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[73] Batch[10] avg_epoch_loss=5.018752\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #quality_metric: host=algo-1, epoch=73, batch=10 train loss <loss>=5.12162656784\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[73] Batch [10]#011Speed: 1435.80 samples/sec#011loss=5.121627\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 693.5241222381592, \"sum\": 693.5241222381592, \"min\": 693.5241222381592}}, \"EndTime\": 1589135677.458766, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135676.764833}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=948.636496346 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #quality_metric: host=algo-1, epoch=73, train loss <loss>=5.01875222813\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[74] Batch[0] avg_epoch_loss=5.470828\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #quality_metric: host=algo-1, epoch=74, batch=0 train loss <loss>=5.4708275795\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[74] Batch[5] avg_epoch_loss=5.020104\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] #quality_metric: host=algo-1, epoch=74, batch=5 train loss <loss>=5.02010424932\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:37 INFO 140026428319552] Epoch[74] Batch [5]#011Speed: 1369.78 samples/sec#011loss=5.020104\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] Epoch[74] Batch[10] avg_epoch_loss=4.984769\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #quality_metric: host=algo-1, epoch=74, batch=10 train loss <loss>=4.94236764908\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] Epoch[74] Batch [10]#011Speed: 1373.80 samples/sec#011loss=4.942368\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] processed a total of 663 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 680.1531314849854, \"sum\": 680.1531314849854, \"min\": 680.1531314849854}}, \"EndTime\": 1589135678.139399, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135677.458835}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=974.621623042 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #quality_metric: host=algo-1, epoch=74, train loss <loss>=4.98476943103\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] Epoch[75] Batch[0] avg_epoch_loss=4.614815\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #quality_metric: host=algo-1, epoch=75, batch=0 train loss <loss>=4.6148147583\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] Epoch[75] Batch[5] avg_epoch_loss=4.916075\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #quality_metric: host=algo-1, epoch=75, batch=5 train loss <loss>=4.9160750707\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] Epoch[75] Batch [5]#011Speed: 1491.60 samples/sec#011loss=4.916075\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] Epoch[75] Batch[10] avg_epoch_loss=5.073571\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #quality_metric: host=algo-1, epoch=75, batch=10 train loss <loss>=5.26256504059\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] Epoch[75] Batch [10]#011Speed: 1255.79 samples/sec#011loss=5.262565\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] processed a total of 688 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 699.195146560669, \"sum\": 699.195146560669, \"min\": 699.195146560669}}, \"EndTime\": 1589135678.839082, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135678.139476}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=983.83386849 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] #quality_metric: host=algo-1, epoch=75, train loss <loss>=5.07357051156\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:38 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] Epoch[76] Batch[0] avg_epoch_loss=4.812509\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] #quality_metric: host=algo-1, epoch=76, batch=0 train loss <loss>=4.81250858307\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] Epoch[76] Batch[5] avg_epoch_loss=4.963556\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] #quality_metric: host=algo-1, epoch=76, batch=5 train loss <loss>=4.9635562102\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] Epoch[76] Batch [5]#011Speed: 1361.62 samples/sec#011loss=4.963556\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] Epoch[76] Batch[10] avg_epoch_loss=5.114987\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] #quality_metric: host=algo-1, epoch=76, batch=10 train loss <loss>=5.29670467377\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] Epoch[76] Batch [10]#011Speed: 1352.95 samples/sec#011loss=5.296705\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] processed a total of 653 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 697.9598999023438, \"sum\": 697.9598999023438, \"min\": 697.9598999023438}}, \"EndTime\": 1589135679.537521, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135678.839158}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=935.434930302 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] #quality_metric: host=algo-1, epoch=76, train loss <loss>=5.11498733\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] Epoch[77] Batch[0] avg_epoch_loss=5.327149\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:39 INFO 140026428319552] #quality_metric: host=algo-1, epoch=77, batch=0 train loss <loss>=5.32714891434\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] Epoch[77] Batch[5] avg_epoch_loss=5.044449\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #quality_metric: host=algo-1, epoch=77, batch=5 train loss <loss>=5.04444885254\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] Epoch[77] Batch [5]#011Speed: 1177.47 samples/sec#011loss=5.044449\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] Epoch[77] Batch[10] avg_epoch_loss=4.991215\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #quality_metric: host=algo-1, epoch=77, batch=10 train loss <loss>=4.92733516693\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] Epoch[77] Batch [10]#011Speed: 1419.24 samples/sec#011loss=4.927335\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] processed a total of 654 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 718.9490795135498, \"sum\": 718.9490795135498, \"min\": 718.9490795135498}}, \"EndTime\": 1589135680.25695, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135679.537598}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=909.524452709 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #quality_metric: host=algo-1, epoch=77, train loss <loss>=4.99121535908\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] Epoch[78] Batch[0] avg_epoch_loss=4.961898\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #quality_metric: host=algo-1, epoch=78, batch=0 train loss <loss>=4.96189785004\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] Epoch[78] Batch[5] avg_epoch_loss=4.890237\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #quality_metric: host=algo-1, epoch=78, batch=5 train loss <loss>=4.89023669561\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] Epoch[78] Batch [5]#011Speed: 1428.17 samples/sec#011loss=4.890237\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] processed a total of 610 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 629.4269561767578, \"sum\": 629.4269561767578, \"min\": 629.4269561767578}}, \"EndTime\": 1589135680.886861, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135680.257024}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=968.95380918 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #progress_metric: host=algo-1, completed 19 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] #quality_metric: host=algo-1, epoch=78, train loss <loss>=4.9267636776\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:40 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] Epoch[79] Batch[0] avg_epoch_loss=5.252294\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] #quality_metric: host=algo-1, epoch=79, batch=0 train loss <loss>=5.25229358673\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] Epoch[79] Batch[5] avg_epoch_loss=4.906216\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] #quality_metric: host=algo-1, epoch=79, batch=5 train loss <loss>=4.90621606509\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] Epoch[79] Batch [5]#011Speed: 1496.91 samples/sec#011loss=4.906216\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] processed a total of 622 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 646.8830108642578, \"sum\": 646.8830108642578, \"min\": 646.8830108642578}}, \"EndTime\": 1589135681.534289, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135680.886943}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=961.401817588 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] #quality_metric: host=algo-1, epoch=79, train loss <loss>=4.97968029976\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] Epoch[80] Batch[0] avg_epoch_loss=4.689404\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] #quality_metric: host=algo-1, epoch=80, batch=0 train loss <loss>=4.68940448761\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] Epoch[80] Batch[5] avg_epoch_loss=4.943358\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] #quality_metric: host=algo-1, epoch=80, batch=5 train loss <loss>=4.94335834185\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:41 INFO 140026428319552] Epoch[80] Batch [5]#011Speed: 1451.55 samples/sec#011loss=4.943358\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] Epoch[80] Batch[10] avg_epoch_loss=5.028209\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #quality_metric: host=algo-1, epoch=80, batch=10 train loss <loss>=5.13002929687\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] Epoch[80] Batch [10]#011Speed: 1449.29 samples/sec#011loss=5.130029\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 645.5240249633789, \"sum\": 645.5240249633789, \"min\": 645.5240249633789}}, \"EndTime\": 1589135682.180335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135681.534349}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1028.44466043 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #quality_metric: host=algo-1, epoch=80, train loss <loss>=5.02820877595\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] Epoch[81] Batch[0] avg_epoch_loss=5.685406\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #quality_metric: host=algo-1, epoch=81, batch=0 train loss <loss>=5.68540620804\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] Epoch[81] Batch[5] avg_epoch_loss=5.420832\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #quality_metric: host=algo-1, epoch=81, batch=5 train loss <loss>=5.42083239555\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] Epoch[81] Batch [5]#011Speed: 1505.74 samples/sec#011loss=5.420832\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] Epoch[81] Batch[10] avg_epoch_loss=5.307427\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #quality_metric: host=algo-1, epoch=81, batch=10 train loss <loss>=5.17134137154\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] Epoch[81] Batch [10]#011Speed: 1363.10 samples/sec#011loss=5.171341\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] processed a total of 664 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 670.3269481658936, \"sum\": 670.3269481658936, \"min\": 670.3269481658936}}, \"EndTime\": 1589135682.851144, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135682.18041}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=990.401825315 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] #quality_metric: host=algo-1, epoch=81, train loss <loss>=5.30742738464\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:42 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] Epoch[82] Batch[0] avg_epoch_loss=5.373530\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] #quality_metric: host=algo-1, epoch=82, batch=0 train loss <loss>=5.37353038788\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] Epoch[82] Batch[5] avg_epoch_loss=5.285795\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] #quality_metric: host=algo-1, epoch=82, batch=5 train loss <loss>=5.28579545021\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] Epoch[82] Batch [5]#011Speed: 1488.95 samples/sec#011loss=5.285795\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] processed a total of 640 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 616.2590980529785, \"sum\": 616.2590980529785, \"min\": 616.2590980529785}}, \"EndTime\": 1589135683.467893, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135682.851219}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1038.28842736 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] #quality_metric: host=algo-1, epoch=82, train loss <loss>=5.29992079735\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] Epoch[83] Batch[0] avg_epoch_loss=5.087463\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] #quality_metric: host=algo-1, epoch=83, batch=0 train loss <loss>=5.08746337891\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] Epoch[83] Batch[5] avg_epoch_loss=5.069817\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] #quality_metric: host=algo-1, epoch=83, batch=5 train loss <loss>=5.06981714567\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:43 INFO 140026428319552] Epoch[83] Batch [5]#011Speed: 1412.43 samples/sec#011loss=5.069817\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 634.6540451049805, \"sum\": 634.6540451049805, \"min\": 634.6540451049805}}, \"EndTime\": 1589135684.103095, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135683.467996}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1001.95364742 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #quality_metric: host=algo-1, epoch=83, train loss <loss>=5.05092477798\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] Epoch[84] Batch[0] avg_epoch_loss=5.092697\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #quality_metric: host=algo-1, epoch=84, batch=0 train loss <loss>=5.09269714355\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] Epoch[84] Batch[5] avg_epoch_loss=4.989334\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #quality_metric: host=algo-1, epoch=84, batch=5 train loss <loss>=4.98933418592\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] Epoch[84] Batch [5]#011Speed: 1487.46 samples/sec#011loss=4.989334\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] Epoch[84] Batch[10] avg_epoch_loss=4.982225\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #quality_metric: host=algo-1, epoch=84, batch=10 train loss <loss>=4.97369499207\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] Epoch[84] Batch [10]#011Speed: 1432.58 samples/sec#011loss=4.973695\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] processed a total of 675 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 650.9749889373779, \"sum\": 650.9749889373779, \"min\": 650.9749889373779}}, \"EndTime\": 1589135684.754629, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135684.103163}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1036.72621931 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #quality_metric: host=algo-1, epoch=84, train loss <loss>=4.98222546144\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] Epoch[85] Batch[0] avg_epoch_loss=4.663744\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:44 INFO 140026428319552] #quality_metric: host=algo-1, epoch=85, batch=0 train loss <loss>=4.66374397278\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] Epoch[85] Batch[5] avg_epoch_loss=4.600572\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] #quality_metric: host=algo-1, epoch=85, batch=5 train loss <loss>=4.60057202975\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] Epoch[85] Batch [5]#011Speed: 1478.82 samples/sec#011loss=4.600572\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] processed a total of 628 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 651.0851383209229, \"sum\": 651.0851383209229, \"min\": 651.0851383209229}}, \"EndTime\": 1589135685.406191, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135684.754706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=964.39280102 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] #quality_metric: host=algo-1, epoch=85, train loss <loss>=4.71980757713\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] Epoch[86] Batch[0] avg_epoch_loss=4.999504\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] #quality_metric: host=algo-1, epoch=86, batch=0 train loss <loss>=4.99950408936\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] Epoch[86] Batch[5] avg_epoch_loss=4.890929\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] #quality_metric: host=algo-1, epoch=86, batch=5 train loss <loss>=4.89092858632\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:45 INFO 140026428319552] Epoch[86] Batch [5]#011Speed: 1476.96 samples/sec#011loss=4.890929\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[86] Batch[10] avg_epoch_loss=4.962585\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #quality_metric: host=algo-1, epoch=86, batch=10 train loss <loss>=5.04857320786\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[86] Batch [10]#011Speed: 1413.20 samples/sec#011loss=5.048573\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 648.2808589935303, \"sum\": 648.2808589935303, \"min\": 648.2808589935303}}, \"EndTime\": 1589135686.05503, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135685.406262}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1050.29526085 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #quality_metric: host=algo-1, epoch=86, train loss <loss>=4.96258523247\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[87] Batch[0] avg_epoch_loss=5.024175\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #quality_metric: host=algo-1, epoch=87, batch=0 train loss <loss>=5.02417516708\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[87] Batch[5] avg_epoch_loss=4.905671\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #quality_metric: host=algo-1, epoch=87, batch=5 train loss <loss>=4.90567111969\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[87] Batch [5]#011Speed: 1245.23 samples/sec#011loss=4.905671\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[87] Batch[10] avg_epoch_loss=4.848444\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #quality_metric: host=algo-1, epoch=87, batch=10 train loss <loss>=4.77977199554\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[87] Batch [10]#011Speed: 1386.54 samples/sec#011loss=4.779772\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] processed a total of 645 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 686.5389347076416, \"sum\": 686.5389347076416, \"min\": 686.5389347076416}}, \"EndTime\": 1589135686.742085, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135686.055099}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=939.331068563 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #quality_metric: host=algo-1, epoch=87, train loss <loss>=4.84844424508\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] Epoch[88] Batch[0] avg_epoch_loss=5.074608\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:46 INFO 140026428319552] #quality_metric: host=algo-1, epoch=88, batch=0 train loss <loss>=5.07460832596\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] Epoch[88] Batch[5] avg_epoch_loss=4.945869\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=88, batch=5 train loss <loss>=4.94586928686\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] Epoch[88] Batch [5]#011Speed: 1408.93 samples/sec#011loss=4.945869\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] Epoch[88] Batch[10] avg_epoch_loss=4.908594\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=88, batch=10 train loss <loss>=4.86386470795\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] Epoch[88] Batch [10]#011Speed: 1431.50 samples/sec#011loss=4.863865\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] processed a total of 673 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 671.4119911193848, \"sum\": 671.4119911193848, \"min\": 671.4119911193848}}, \"EndTime\": 1589135687.414071, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135686.742168}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1002.19791406 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=88, train loss <loss>=4.90859447826\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] Epoch[89] Batch[0] avg_epoch_loss=5.091031\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=89, batch=0 train loss <loss>=5.09103059769\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] Epoch[89] Batch[5] avg_epoch_loss=4.901903\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] #quality_metric: host=algo-1, epoch=89, batch=5 train loss <loss>=4.90190291405\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:47 INFO 140026428319552] Epoch[89] Batch [5]#011Speed: 1443.91 samples/sec#011loss=4.901903\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] Epoch[89] Batch[10] avg_epoch_loss=4.866064\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=89, batch=10 train loss <loss>=4.82305641174\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] Epoch[89] Batch [10]#011Speed: 1422.78 samples/sec#011loss=4.823056\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] processed a total of 647 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 704.805850982666, \"sum\": 704.805850982666, \"min\": 704.805850982666}}, \"EndTime\": 1589135688.119359, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135687.414148}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=917.845133032 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=89, train loss <loss>=4.86606359482\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] Epoch[90] Batch[0] avg_epoch_loss=4.517090\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=90, batch=0 train loss <loss>=4.51708984375\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] Epoch[90] Batch[5] avg_epoch_loss=4.855079\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=90, batch=5 train loss <loss>=4.85507861773\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] Epoch[90] Batch [5]#011Speed: 1458.08 samples/sec#011loss=4.855079\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] Epoch[90] Batch[10] avg_epoch_loss=4.909837\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=90, batch=10 train loss <loss>=4.97554607391\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] Epoch[90] Batch [10]#011Speed: 1436.79 samples/sec#011loss=4.975546\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] processed a total of 674 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 688.5349750518799, \"sum\": 688.5349750518799, \"min\": 688.5349750518799}}, \"EndTime\": 1589135688.808349, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135688.11943}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=978.733423187 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] #quality_metric: host=algo-1, epoch=90, train loss <loss>=4.90983655236\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:48 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] Epoch[91] Batch[0] avg_epoch_loss=5.377658\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=91, batch=0 train loss <loss>=5.37765789032\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] Epoch[91] Batch[5] avg_epoch_loss=5.044869\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=91, batch=5 train loss <loss>=5.04486918449\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] Epoch[91] Batch [5]#011Speed: 1473.40 samples/sec#011loss=5.044869\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 617.9780960083008, \"sum\": 617.9780960083008, \"min\": 617.9780960083008}}, \"EndTime\": 1589135689.426809, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135688.808426}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1032.2055118 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=91, train loss <loss>=4.94568543434\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] Epoch[92] Batch[0] avg_epoch_loss=4.547922\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=92, batch=0 train loss <loss>=4.54792165756\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] Epoch[92] Batch[5] avg_epoch_loss=4.763290\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] #quality_metric: host=algo-1, epoch=92, batch=5 train loss <loss>=4.76329048475\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:49 INFO 140026428319552] Epoch[92] Batch [5]#011Speed: 1298.24 samples/sec#011loss=4.763290\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] Epoch[92] Batch[10] avg_epoch_loss=4.860030\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=92, batch=10 train loss <loss>=4.97611694336\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] Epoch[92] Batch [10]#011Speed: 1361.21 samples/sec#011loss=4.976117\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] processed a total of 690 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 709.0730667114258, \"sum\": 709.0730667114258, \"min\": 709.0730667114258}}, \"EndTime\": 1589135690.136404, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135689.426889}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=972.96171619 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=92, train loss <loss>=4.86002978412\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] Epoch[93] Batch[0] avg_epoch_loss=4.628958\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=93, batch=0 train loss <loss>=4.62895822525\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] Epoch[93] Batch[5] avg_epoch_loss=4.819191\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=93, batch=5 train loss <loss>=4.81919089953\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] Epoch[93] Batch [5]#011Speed: 1334.93 samples/sec#011loss=4.819191\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] processed a total of 633 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 621.4330196380615, \"sum\": 621.4330196380615, \"min\": 621.4330196380615}}, \"EndTime\": 1589135690.758367, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135690.136472}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1018.42311407 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=93, train loss <loss>=4.83149657249\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] Epoch[94] Batch[0] avg_epoch_loss=5.216052\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:50 INFO 140026428319552] #quality_metric: host=algo-1, epoch=94, batch=0 train loss <loss>=5.21605157852\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] Epoch[94] Batch[5] avg_epoch_loss=5.003830\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=94, batch=5 train loss <loss>=5.00383035342\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] Epoch[94] Batch [5]#011Speed: 1482.37 samples/sec#011loss=5.003830\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] Epoch[94] Batch[10] avg_epoch_loss=4.780247\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=94, batch=10 train loss <loss>=4.51194758415\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] Epoch[94] Batch [10]#011Speed: 1380.95 samples/sec#011loss=4.511948\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] processed a total of 649 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 678.7528991699219, \"sum\": 678.7528991699219, \"min\": 678.7528991699219}}, \"EndTime\": 1589135691.437631, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135690.758447}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=956.013223528 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=94, train loss <loss>=4.78024727648\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] Epoch[95] Batch[0] avg_epoch_loss=5.158528\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=95, batch=0 train loss <loss>=5.15852832794\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] Epoch[95] Batch[5] avg_epoch_loss=5.033369\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] #quality_metric: host=algo-1, epoch=95, batch=5 train loss <loss>=5.03336866697\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:51 INFO 140026428319552] Epoch[95] Batch [5]#011Speed: 1370.60 samples/sec#011loss=5.033369\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] Epoch[95] Batch[10] avg_epoch_loss=4.929332\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=95, batch=10 train loss <loss>=4.80448827744\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] Epoch[95] Batch [10]#011Speed: 1405.45 samples/sec#011loss=4.804488\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] processed a total of 658 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 678.3890724182129, \"sum\": 678.3890724182129, \"min\": 678.3890724182129}}, \"EndTime\": 1589135692.116506, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135691.437706}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=969.786042485 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=95, train loss <loss>=4.92933212627\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] Epoch[96] Batch[0] avg_epoch_loss=4.916426\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=96, batch=0 train loss <loss>=4.91642570496\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] Epoch[96] Batch[5] avg_epoch_loss=4.908071\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=96, batch=5 train loss <loss>=4.90807080269\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] Epoch[96] Batch [5]#011Speed: 1506.57 samples/sec#011loss=4.908071\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] Epoch[96] Batch[10] avg_epoch_loss=4.918324\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=96, batch=10 train loss <loss>=4.93062782288\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] Epoch[96] Batch [10]#011Speed: 1325.52 samples/sec#011loss=4.930628\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] processed a total of 656 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 699.0268230438232, \"sum\": 699.0268230438232, \"min\": 699.0268230438232}}, \"EndTime\": 1589135692.816026, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135692.116582}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=938.295843855 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] #quality_metric: host=algo-1, epoch=96, train loss <loss>=4.91832399368\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:52 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] Epoch[97] Batch[0] avg_epoch_loss=4.889688\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=97, batch=0 train loss <loss>=4.88968753815\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] Epoch[97] Batch[5] avg_epoch_loss=4.927878\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=97, batch=5 train loss <loss>=4.92787837982\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] Epoch[97] Batch [5]#011Speed: 1470.81 samples/sec#011loss=4.927878\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] processed a total of 607 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 621.0629940032959, \"sum\": 621.0629940032959, \"min\": 621.0629940032959}}, \"EndTime\": 1589135693.437601, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135692.816103}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=977.173887912 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=97, train loss <loss>=4.97080626488\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] Epoch[98] Batch[0] avg_epoch_loss=4.855039\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=98, batch=0 train loss <loss>=4.85503911972\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] Epoch[98] Batch[5] avg_epoch_loss=5.150934\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] #quality_metric: host=algo-1, epoch=98, batch=5 train loss <loss>=5.1509335041\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:53 INFO 140026428319552] Epoch[98] Batch [5]#011Speed: 1489.82 samples/sec#011loss=5.150934\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] processed a total of 625 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 620.6450462341309, \"sum\": 620.6450462341309, \"min\": 620.6450462341309}}, \"EndTime\": 1589135694.058767, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135693.437681}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1006.82730183 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #progress_metric: host=algo-1, completed 24 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=98, train loss <loss>=4.85009486675\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] Epoch[99] Batch[0] avg_epoch_loss=4.681884\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=99, batch=0 train loss <loss>=4.68188381195\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] Epoch[99] Batch[5] avg_epoch_loss=4.933884\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=99, batch=5 train loss <loss>=4.93388406436\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] Epoch[99] Batch [5]#011Speed: 1455.39 samples/sec#011loss=4.933884\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] processed a total of 639 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 627.8688907623291, \"sum\": 627.8688907623291, \"min\": 627.8688907623291}}, \"EndTime\": 1589135694.68716, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135694.058847}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1017.54022688 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=99, train loss <loss>=4.91908946037\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] Epoch[100] Batch[0] avg_epoch_loss=4.864681\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:54 INFO 140026428319552] #quality_metric: host=algo-1, epoch=100, batch=0 train loss <loss>=4.86468076706\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] Epoch[100] Batch[5] avg_epoch_loss=4.904813\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=100, batch=5 train loss <loss>=4.90481281281\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] Epoch[100] Batch [5]#011Speed: 1347.79 samples/sec#011loss=4.904813\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] Epoch[100] Batch[10] avg_epoch_loss=4.787406\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=100, batch=10 train loss <loss>=4.64651784897\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] Epoch[100] Batch [10]#011Speed: 1380.67 samples/sec#011loss=4.646518\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] processed a total of 681 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 681.6961765289307, \"sum\": 681.6961765289307, \"min\": 681.6961765289307}}, \"EndTime\": 1589135695.369381, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135694.68724}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=998.81946374 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=100, train loss <loss>=4.78740601106\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] Epoch[101] Batch[0] avg_epoch_loss=4.631684\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=101, batch=0 train loss <loss>=4.63168382645\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] Epoch[101] Batch[5] avg_epoch_loss=4.803294\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=101, batch=5 train loss <loss>=4.80329354604\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] Epoch[101] Batch [5]#011Speed: 1472.63 samples/sec#011loss=4.803294\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] processed a total of 638 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 627.2869110107422, \"sum\": 627.2869110107422, \"min\": 627.2869110107422}}, \"EndTime\": 1589135695.997149, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135695.369456}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1016.88868081 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] #quality_metric: host=algo-1, epoch=101, train loss <loss>=4.83321671486\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:55 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] Epoch[102] Batch[0] avg_epoch_loss=4.860910\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=102, batch=0 train loss <loss>=4.86090993881\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] Epoch[102] Batch[5] avg_epoch_loss=4.756762\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=102, batch=5 train loss <loss>=4.75676234563\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] Epoch[102] Batch [5]#011Speed: 1509.22 samples/sec#011loss=4.756762\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] Epoch[102] Batch[10] avg_epoch_loss=4.680237\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=102, batch=10 train loss <loss>=4.58840637207\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] Epoch[102] Batch [10]#011Speed: 1359.64 samples/sec#011loss=4.588406\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] processed a total of 644 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 699.4359493255615, \"sum\": 699.4359493255615, \"min\": 699.4359493255615}}, \"EndTime\": 1589135696.697095, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135695.997231}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=920.602276957 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=102, train loss <loss>=4.6802369031\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] Epoch[103] Batch[0] avg_epoch_loss=5.471140\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:56 INFO 140026428319552] #quality_metric: host=algo-1, epoch=103, batch=0 train loss <loss>=5.47114038467\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] Epoch[103] Batch[5] avg_epoch_loss=4.881214\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=103, batch=5 train loss <loss>=4.88121406237\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] Epoch[103] Batch [5]#011Speed: 1464.03 samples/sec#011loss=4.881214\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] Epoch[103] Batch[10] avg_epoch_loss=4.844120\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=103, batch=10 train loss <loss>=4.79960737228\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] Epoch[103] Batch [10]#011Speed: 1457.72 samples/sec#011loss=4.799607\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] processed a total of 709 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 705.7781219482422, \"sum\": 705.7781219482422, \"min\": 705.7781219482422}}, \"EndTime\": 1589135697.403334, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135696.697167}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1004.40146045 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=103, train loss <loss>=4.62188762426\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] Epoch[104] Batch[0] avg_epoch_loss=4.901870\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=104, batch=0 train loss <loss>=4.9018702507\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] Epoch[104] Batch[5] avg_epoch_loss=4.804757\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] #quality_metric: host=algo-1, epoch=104, batch=5 train loss <loss>=4.80475727717\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:57 INFO 140026428319552] Epoch[104] Batch [5]#011Speed: 1504.54 samples/sec#011loss=4.804757\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] processed a total of 636 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 605.0570011138916, \"sum\": 605.0570011138916, \"min\": 605.0570011138916}}, \"EndTime\": 1589135698.008907, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135697.403414}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1050.94268658 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=104, train loss <loss>=4.82400164604\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] Epoch[105] Batch[0] avg_epoch_loss=5.262448\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=105, batch=0 train loss <loss>=5.26244831085\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] Epoch[105] Batch[5] avg_epoch_loss=4.917890\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=105, batch=5 train loss <loss>=4.91788975398\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] Epoch[105] Batch [5]#011Speed: 1497.85 samples/sec#011loss=4.917890\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 618.9000606536865, \"sum\": 618.9000606536865, \"min\": 618.9000606536865}}, \"EndTime\": 1589135698.62833, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135698.008985}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1019.35790684 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=105, train loss <loss>=4.82808141708\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] Epoch[106] Batch[0] avg_epoch_loss=4.676037\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:58 INFO 140026428319552] #quality_metric: host=algo-1, epoch=106, batch=0 train loss <loss>=4.67603683472\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] Epoch[106] Batch[5] avg_epoch_loss=4.834742\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=106, batch=5 train loss <loss>=4.83474238714\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] Epoch[106] Batch [5]#011Speed: 1456.46 samples/sec#011loss=4.834742\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] processed a total of 631 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 603.2900810241699, \"sum\": 603.2900810241699, \"min\": 603.2900810241699}}, \"EndTime\": 1589135699.232156, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135698.628411}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=1045.75155928 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=106, train loss <loss>=4.66751408577\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] Epoch[107] Batch[0] avg_epoch_loss=4.525241\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=107, batch=0 train loss <loss>=4.52524089813\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] Epoch[107] Batch[5] avg_epoch_loss=4.738932\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=107, batch=5 train loss <loss>=4.7389318943\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] Epoch[107] Batch [5]#011Speed: 1478.29 samples/sec#011loss=4.738932\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] Epoch[107] Batch[10] avg_epoch_loss=5.062688\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=107, batch=10 train loss <loss>=5.45119514465\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] Epoch[107] Batch [10]#011Speed: 1355.51 samples/sec#011loss=5.451195\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] processed a total of 642 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 650.8760452270508, \"sum\": 650.8760452270508, \"min\": 650.8760452270508}}, \"EndTime\": 1589135699.883621, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135699.23223}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=986.216255771 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] #quality_metric: host=algo-1, epoch=107, train loss <loss>=5.06268791719\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:34:59 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Epoch[108] Batch[0] avg_epoch_loss=4.334298\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=108, batch=0 train loss <loss>=4.33429813385\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Epoch[108] Batch[5] avg_epoch_loss=4.853285\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=108, batch=5 train loss <loss>=4.85328499476\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Epoch[108] Batch [5]#011Speed: 1417.04 samples/sec#011loss=4.853285\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Epoch[108] Batch[10] avg_epoch_loss=4.755573\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=108, batch=10 train loss <loss>=4.63831920624\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Epoch[108] Batch [10]#011Speed: 1370.17 samples/sec#011loss=4.638319\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] processed a total of 672 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 698.7869739532471, \"sum\": 698.7869739532471, \"min\": 698.7869739532471}}, \"EndTime\": 1589135700.582964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135699.883684}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #throughput_metric: host=algo-1, train throughput=961.516215384 records/second\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #quality_metric: host=algo-1, epoch=108, train loss <loss>=4.75557327271\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] loss did not improve\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Loading parameters from best epoch (68)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 9.636163711547852, \"sum\": 9.636163711547852, \"min\": 9.636163711547852}}, \"EndTime\": 1589135700.593142, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135700.583038}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] stopping training now\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Final loss: 4.52659548413 (occurred at epoch 68)\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] #quality_metric: host=algo-1, train final_loss <loss>=4.52659548413\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 WARNING 140026428319552] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 166.97001457214355, \"sum\": 166.97001457214355, \"min\": 166.97001457214355}}, \"EndTime\": 1589135700.760787, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135700.593203}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 218.1251049041748, \"sum\": 218.1251049041748, \"min\": 218.1251049041748}}, \"EndTime\": 1589135700.811911, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135700.760864}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 9.010076522827148, \"sum\": 9.010076522827148, \"min\": 9.010076522827148}}, \"EndTime\": 1589135700.821063, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135700.811997}\n",
      "\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[05/10/2020 18:35:00 INFO 140026428319552] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 74071.79093360901, \"sum\": 74071.79093360901, \"min\": 74071.79093360901}, \"setuptime\": {\"count\": 1, \"max\": 8.739948272705078, \"sum\": 8.739948272705078, \"min\": 8.739948272705078}}, \"EndTime\": 1589135700.831531, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1589135700.821134}\n",
      "\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "2020-05-10 18:35:12 Uploading - Uploading generated training model\n",
      "2020-05-10 18:35:12 Completed - Training job completed\n",
      "Training seconds: 132\n",
      "Billable seconds: 132\n"
     ]
    }
   ],
   "source": [
    "data_channels = {\n",
    "    \"train\": \"s3://databucket-covid-19/\"\n",
    "}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "job_name = estimator.latest_training_job.name\n",
    "\n",
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=job_name,\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    deployment_image=image_name,\n",
    "    role=role\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor = sagemaker.predictor.RealTimePredictor(endpoint_name,sagemaker_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = json.dumps({\n",
    "    \"instances\": json_content,\n",
    "    \"configuration\": {\n",
    "        \"num_samples\": 50,\n",
    "        \"output_types\": [\"mean\"]\n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = predictor.predict(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sagemaker_session.delete_endpoint(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
